{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcampb188/Stress-Detection-in-PINN-Model/blob/main/Stress_Detection_in_PINN_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload WESAD dataset & start prepping\n",
        "\n",
        "\n",
        "*   Clean, prepare and pre-process data\n",
        "*   Define labels and null values removed\n",
        "*   Begin feature extraction\n",
        "\n"
      ],
      "metadata": {
        "id": "5QqVpMbdc2pS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download necessary packages for data processing.\n"
      ],
      "metadata": {
        "id": "8WOrfmtHPrHW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr5YSf9t5P4D",
        "outputId": "44b0e30e-6d92-4a4a-a688-891aae54d041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting neurokit2\n",
            "  Downloading neurokit2-0.2.12-py2.py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from neurokit2) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from neurokit2) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from neurokit2) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from neurokit2) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from neurokit2) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from neurokit2) (3.10.0)\n",
            "Requirement already satisfied: PyWavelets>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from neurokit2) (1.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->neurokit2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->neurokit2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->neurokit2) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->neurokit2) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->neurokit2) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->neurokit2) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->neurokit2) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->neurokit2) (2.9.0.post0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->neurokit2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->neurokit2) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->neurokit2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->neurokit2) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->neurokit2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->neurokit2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->neurokit2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->neurokit2) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->neurokit2) (1.17.0)\n",
            "Downloading neurokit2-0.2.12-py2.py3-none-any.whl (708 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.4/708.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: neurokit2\n",
            "Successfully installed neurokit2-0.2.12\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install numpy scipy scikit-learn\n",
        "!pip install neurokit2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gduwXEry6A50"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import scipy.io as sio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload the WESAD dataset from the Kaggle site."
      ],
      "metadata": {
        "id": "siYd5eSVkWwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Set up Kaggle API credentials as environment variables for the shell\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# Use the environment variables in the shell command\n",
        "!export KAGGLE_USERNAME=$KAGGLE_USERNAME && export KAGGLE_KEY=$KAGGLE_KEY && kaggle datasets download -d mohamedasem318/wesad-full-dataset -p /content/data --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu42r2t-X1Kr",
        "outputId": "58bf8c0e-2594-496e-fd18-7cacb336e6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedasem318/wesad-full-dataset\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Downloading wesad-full-dataset.zip to /content/data\n",
            "100% 2.43G/2.43G [00:20<00:00, 115MB/s] \n",
            "100% 2.43G/2.43G [00:20<00:00, 126MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67316770"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "#### Chest had more available data than wrist - will continue to use this moving forward.\n",
        "#### First checking how many null variables are present. From here I will determine whether to remove them or impute.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cea47561",
        "outputId": "79bd9c92-1d63-4994-e363-ee7ac3d68395",
        "collapsed": true
      },
      "source": [
        "# Review wrist and chest data\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import scipy.io as sio\n",
        "\n",
        "# Check files in the WESAD FOLDER\n",
        "wesad_dir = '/content/data/WESAD/'\n",
        "subject_dirs = glob.glob(os.path.join(wesad_dir, 'S*'))\n",
        "\n",
        "# Sampling one .pkl file\n",
        "if subject_dirs:\n",
        "    sample_subject_dir = subject_dirs[0]\n",
        "    pkl_files = glob.glob(os.path.join(sample_subject_dir, '*.pkl'))\n",
        "    if pkl_files:\n",
        "        sample_file = pkl_files[0]\n",
        "        print(f\"Loading and examining file: {sample_file}\")\n",
        "\n",
        "        with open(sample_file, 'rb') as f:\n",
        "            data = pickle.load(f, encoding='latin1')\n",
        "\n",
        "        print(\"\\nSample data:\")\n",
        "        print(data.keys())\n",
        "\n",
        "        # Review the data array types\n",
        "        print(\"\\nReview data structure:\")\n",
        "        for key, value in data.items():\n",
        "            print(f\"Key: {key}\")\n",
        "            if isinstance(value, dict):\n",
        "                print(\"  Type: Dictionary\")\n",
        "                print(\"  Keys:\", value.keys())\n",
        "\n",
        "                for sub_key, sub_value in value.items():\n",
        "                    print(f\"    Sub-key: {sub_key}\")\n",
        "                    if isinstance(sub_value, np.ndarray):\n",
        "                        print(f\"      Type: NumPy Array\")\n",
        "                        print(f\"      Shape: {sub_value.shape}\")\n",
        "                        print(f\"      Data Type: {sub_value.dtype}\")\n",
        "                    else:\n",
        "                        print(f\"      Type: {type(sub_value)}\")\n",
        "            elif isinstance(value, np.ndarray):\n",
        "                print(\"  Type: NumPy Array\")\n",
        "                print(\"  Shape: {value.shape}\")\n",
        "                print(\"  Data Type: {value.dtype}\")\n",
        "            else:\n",
        "                print(f\"  Type: {type(value)}\")\n",
        "\n",
        "        # sampling rates\n",
        "\n",
        "        print(\"\\nFinding sampling rates:\")\n",
        "        if 'signal' in data and isinstance(data['signal'], dict):\n",
        "            if 'wrist' in data['signal'] and isinstance(data['signal']['wrist'], dict):\n",
        "                if 'sampling_rate' in data['signal']['wrist']:\n",
        "                     print(f\"Sampling rate for wrist data: {data['signal']['wrist']['sampling_rate']}\")\n",
        "                else:\n",
        "                    print(\"Sampling rate not found in 'signal' -> 'wrist'\")\n",
        "                for sensor, sensor_data in data['signal']['wrist'].items():\n",
        "                     if isinstance(sensor_data, np.ndarray):\n",
        "                         print(f\"  Wrist sensor '{sensor}' data shape: {sensor_data.shape}\")\n",
        "\n",
        "            if 'chest' in data['signal'] and isinstance(data['signal']['chest'], dict):\n",
        "                 if 'sampling_rate' in data['signal']['chest']:\n",
        "                     print(f\"Sampling rate for chest data: {data['signal']['chest']['sampling_rate']}\")\n",
        "                 else:\n",
        "                     print(\"Sampling rate not found in 'signal' -> 'chest'\")\n",
        "                 for sensor, sensor_data in data['signal']['chest'].items():\n",
        "                     if isinstance(sensor_data, np.ndarray):\n",
        "                         print(f\"  Chest sensor '{sensor}' data shape: {sensor_data.shape}\")\n",
        "\n",
        "        if 'label' in data and isinstance(data['label'], np.ndarray):\n",
        "             print(f\"\\nLabel data shape: {data['label'].shape}\")\n",
        "             print(f\"Label data unique values: {np.unique(data['label'])}\")\n",
        "\n",
        "    else:\n",
        "        print(\"No .pkl files found in the sample folder.\")\n",
        "else:\n",
        "    print(\"No subject data found in the WESAD folder.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and examining file: /content/data/WESAD/S15/S15.pkl\n",
            "\n",
            "Sample data:\n",
            "dict_keys(['signal', 'label', 'subject'])\n",
            "\n",
            "Review data structure:\n",
            "Key: signal\n",
            "  Type: Dictionary\n",
            "  Keys: dict_keys(['chest', 'wrist'])\n",
            "    Sub-key: chest\n",
            "      Type: <class 'dict'>\n",
            "    Sub-key: wrist\n",
            "      Type: <class 'dict'>\n",
            "Key: label\n",
            "  Type: NumPy Array\n",
            "  Shape: {value.shape}\n",
            "  Data Type: {value.dtype}\n",
            "Key: subject\n",
            "  Type: <class 'str'>\n",
            "\n",
            "Finding sampling rates:\n",
            "Sampling rate not found in 'signal' -> 'wrist'\n",
            "  Wrist sensor 'ACC' data shape: (168064, 3)\n",
            "  Wrist sensor 'BVP' data shape: (336128, 1)\n",
            "  Wrist sensor 'EDA' data shape: (21008, 1)\n",
            "  Wrist sensor 'TEMP' data shape: (21008, 1)\n",
            "Sampling rate not found in 'signal' -> 'chest'\n",
            "  Chest sensor 'ACC' data shape: (3676400, 3)\n",
            "  Chest sensor 'ECG' data shape: (3676400, 1)\n",
            "  Chest sensor 'EMG' data shape: (3676400, 1)\n",
            "  Chest sensor 'EDA' data shape: (3676400, 1)\n",
            "  Chest sensor 'Temp' data shape: (3676400, 1)\n",
            "  Chest sensor 'Resp' data shape: (3676400, 1)\n",
            "\n",
            "Label data shape: (3676400,)\n",
            "Label data unique values: [0 1 2 3 4 5 6 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d31ee7e6",
        "outputId": "f70202df-62fb-40ac-f2a2-7c2470f32469"
      },
      "source": [
        "# Count available data for wrist and chest in original data\n",
        "print(\"Available data in original data:\")\n",
        "\n",
        "if 'signal' in data:\n",
        "    if 'wrist' in data['signal']:\n",
        "        print(\"\\nWrist Data:\")\n",
        "        for sensor, data_array in data['signal']['wrist'].items():\n",
        "            if isinstance(data_array, np.ndarray):\n",
        "                print(f\"  Sensor '{sensor}': {data_array.shape[0]} samples\")\n",
        "            else:\n",
        "                print(f\"  Sensor '{sensor}': Data not in expected format ({type(data_array)})\")\n",
        "    else:\n",
        "        print(\"\\nNo wrist data found in original data['signal'].\")\n",
        "\n",
        "    if 'chest' in data['signal']:\n",
        "        print(\"\\nChest Data:\")\n",
        "        for sensor, data_array in data['signal']['chest'].items():\n",
        "             if isinstance(data_array, np.ndarray):\n",
        "                print(f\"  Sensor '{sensor}': {data_array.shape[0]} samples\")\n",
        "             else:\n",
        "                print(f\"  Sensor '{sensor}': Data not in expected format ({type(data_array)})\")\n",
        "    else:\n",
        "        print(\"\\nNo chest data found in original data['signal'].\")\n",
        "else:\n",
        "    print(\"\\nNo 'signal' key found in original data.\")\n",
        "\n",
        "if 'label' in data and isinstance(data['label'], np.ndarray):\n",
        "    print(f\"\\nLabel data: {data['label'].shape[0]} samples\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available data in original data:\n",
            "\n",
            "Wrist Data:\n",
            "  Sensor 'ACC': 168064 samples\n",
            "  Sensor 'BVP': 336128 samples\n",
            "  Sensor 'EDA': 21008 samples\n",
            "  Sensor 'TEMP': 21008 samples\n",
            "\n",
            "Chest Data:\n",
            "  Sensor 'ACC': 3676400 samples\n",
            "  Sensor 'ECG': 3676400 samples\n",
            "  Sensor 'EMG': 3676400 samples\n",
            "  Sensor 'EDA': 3676400 samples\n",
            "  Sensor 'Temp': 3676400 samples\n",
            "  Sensor 'Resp': 3676400 samples\n",
            "\n",
            "Label data: 3676400 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc2cf7a",
        "outputId": "ffc7bad3-57dc-416f-cb43-a28991cac74f"
      },
      "source": [
        "# Check for null values in the chest data arrays\n",
        "print(\"\\nChecking for null values in the chest data:\")\n",
        "\n",
        "if 'signal' in data and 'chest' in data['signal']:\n",
        "    for sensor, data_array in data['signal']['chest'].items():\n",
        "        if isinstance(data_array, np.ndarray):\n",
        "\n",
        "            # Check for NaN values\n",
        "            nan_count = np.isnan(data_array).sum()\n",
        "            print(f\"  Sensor '{sensor}': {nan_count} null values\")\n",
        "        else:\n",
        "            print(f\"  Sensor '{sensor}': Data not in expected format ({type(data_array)}), cannot check for nulls.\")\n",
        "else:\n",
        "    print(\"Chest data not found in the 'data' dictionary.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking for null values in the chest data:\n",
            "  Sensor 'ACC': 0 null values\n",
            "  Sensor 'ECG': 0 null values\n",
            "  Sensor 'EMG': 0 null values\n",
            "  Sensor 'EDA': 0 null values\n",
            "  Sensor 'Temp': 0 null values\n",
            "  Sensor 'Resp': 0 null values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing\n",
        "#### Downsample per feature, segment in 60 second windows with 50% overlap"
      ],
      "metadata": {
        "id": "p_iOgFfyDhlH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bae3384",
        "outputId": "39fe7916-b86b-4588-f46d-7d5aa99ec119"
      },
      "source": [
        "from scipy.signal import resample\n",
        "import numpy as np\n",
        "\n",
        "# Downsample data to the specified rates\n",
        "ecg_desired_sampling_rate = 250  # Hz\n",
        "eda_desired_sampling_rate = 8   # Hz\n",
        "resp_desired_sampling_rate = 50  # Hz\n",
        "\n",
        "\n",
        "downsampled_data = {}\n",
        "downsampled_data['signal'] = {}\n",
        "downsampled_data['label'] = data['label']\n",
        "\n",
        "# Define original sampling rates based on typical values for WESAD dataset\n",
        "original_sampling_rate_chest = 700 # Hz for chest sensors\n",
        "\n",
        "# -- Chest Data --\n",
        "if 'chest' in data['signal']:\n",
        "    downsampled_data['signal']['chest'] = {}\n",
        "    for sensor, sensor_data in data['signal']['chest'].items():\n",
        "        if isinstance(sensor_data, np.ndarray):\n",
        "            num_original_samples = sensor_data.shape[0]\n",
        "            original_sampling_rate = original_sampling_rate_chest # Assuming one original sampling rate for all chest sensors\n",
        "\n",
        "            if sensor == 'ECG':\n",
        "                desired_sampling_rate = ecg_desired_sampling_rate\n",
        "            elif sensor == 'EDA':\n",
        "                desired_sampling_rate = eda_desired_sampling_rate\n",
        "            elif sensor == 'Resp':\n",
        "                desired_sampling_rate = resp_desired_sampling_rate\n",
        "            else:\n",
        "                # Keep original sampling rate for other chest sensors or skip\n",
        "                downsampled_data['signal']['chest'][sensor] = sensor_data\n",
        "                print(f\"Kept original sampling rate for chest sensor '{sensor}'. Shape: {sensor_data.shape}\")\n",
        "                continue # Skip downsampling for other sensors\n",
        "\n",
        "            num_desired_samples = int(num_original_samples * (desired_sampling_rate / original_sampling_rate))\n",
        "\n",
        "             # Resample each column if it's multi-dimensional\n",
        "            if sensor_data.ndim > 1:\n",
        "                downsampled_sensor_data = np.zeros((num_desired_samples, sensor_data.shape[1]))\n",
        "                for col in range(sensor_data.shape[1]):\n",
        "                    downsampled_sensor_data[:, col] = resample(sensor_data[:, col], num_desired_samples)\n",
        "            else:\n",
        "                downsampled_sensor_data = resample(sensor_data, num_desired_samples)\n",
        "\n",
        "            downsampled_data['signal']['chest'][sensor] = downsampled_sensor_data\n",
        "            print(f\"Downsampled chest sensor '{sensor}'. Original shape: {sensor_data.shape}, Downsampled shape: {downsampled_sensor_data.shape}\")\n",
        "        else:\n",
        "            downsampled_data['signal']['chest'][sensor] = sensor_data\n",
        "\n",
        "\n",
        "print(\"\\nDownsampling and processing complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kept original sampling rate for chest sensor 'ACC'. Shape: (3676400, 3)\n",
            "Downsampled chest sensor 'ECG'. Original shape: (3676400, 1), Downsampled shape: (1313000, 1)\n",
            "Kept original sampling rate for chest sensor 'EMG'. Shape: (3676400, 1)\n",
            "Downsampled chest sensor 'EDA'. Original shape: (3676400, 1), Downsampled shape: (42016, 1)\n",
            "Kept original sampling rate for chest sensor 'Temp'. Shape: (3676400, 1)\n",
            "Downsampled chest sensor 'Resp'. Original shape: (3676400, 1), Downsampled shape: (262600, 1)\n",
            "\n",
            "Downsampling and processing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Labels defined & null values check again"
      ],
      "metadata": {
        "id": "rG6IdQzNJwWF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9abc93cf",
        "outputId": "ab48f48f-bd2c-4e8b-9257-e8e5c76595ff"
      },
      "source": [
        "from scipy.signal import resample\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Define segmentation parameters\n",
        "window_size = 60  # In seconds\n",
        "overlap = 0.5 # For 50% overlap\n",
        "\n",
        "# Step 2: Calculate window size and step size in samples\n",
        "window_samples = int(window_size * desired_sampling_rate)\n",
        "step_samples = int(window_samples * (1 - overlap))\n",
        "\n",
        "segmented_data = []\n",
        "segmented_labels = []\n",
        "\n",
        "# Step 3: Identify the relevant signals (EDA, ECG, Respiration) and segment them.\n",
        "\n",
        "relevant_signals = {\n",
        "    'chest': ['ECG', 'Resp', 'EDA']\n",
        "}\n",
        "\n",
        "# Processing only the 'chest' key data\n",
        "if 'signal' in downsampled_data and 'chest' in downsampled_data['signal']:\n",
        "    for sensor in relevant_signals['chest']:\n",
        "        if sensor in downsampled_data['signal']['chest'] and isinstance(downsampled_data['signal']['chest'][sensor], np.ndarray):\n",
        "            sensor_data = downsampled_data['signal']['chest'][sensor]\n",
        "            label_data = downsampled_data['label']\n",
        "\n",
        "            num_samples = sensor_data.shape[0]\n",
        "\n",
        "            # Iterate through data with the sliding window\n",
        "            for start_sample in range(0, num_samples - window_samples + 1, step_samples):\n",
        "                end_sample = start_sample + window_samples\n",
        "\n",
        "                # Segment the sensor data\n",
        "                segment = sensor_data[start_sample:end_sample]\n",
        "\n",
        "                # Assign label to the segment & find the original label indices.\n",
        "                original_chest_sampling_rate = 700 # Approximate original sampling rate\n",
        "                downsampling_factor_chest = original_chest_sampling_rate / desired_sampling_rate\n",
        "\n",
        "                # Calculate corresponding original sample indices\n",
        "                original_start_sample = int(start_sample * downsampling_factor_chest)\n",
        "                original_end_sample = int(end_sample * downsampling_factor_chest)\n",
        "\n",
        "                # Ensure the original indices don't exceed the bounds of the label data\n",
        "                original_end_sample = min(original_end_sample, len(label_data))\n",
        "                original_start_sample = min(original_start_sample, original_end_sample)\n",
        "\n",
        "\n",
        "                segment_labels_original = label_data[original_start_sample:original_end_sample]\n",
        "\n",
        "                # Assign labels based on the provided meanings:\n",
        "                # 0 = undefined, 1 = not stressed, 2 = stress, 3 = entertained, 4 = meditation, 5/6/7 = should be ignored\n",
        "                if len(segment_labels_original) > 0:\n",
        "                    unique_labels, counts = np.unique(segment_labels_original, return_counts=True)\n",
        "                    most_frequent_label = unique_labels[np.argmax(counts)]\n",
        "\n",
        "                    # Assign multi-class labels based on the most frequent original label\n",
        "                    if most_frequent_label in [0, 1, 2, 3, 4]:\n",
        "                        # Map original labels to desired output labels\n",
        "                        # 0 -> 0 (undefined)\n",
        "                        # 1 -> 1 (not stressed)\n",
        "                        # 2 -> 2 (stressed)\n",
        "                        # 3 -> 3 (entertained)\n",
        "                        # 4 -> 4 (meditating)\n",
        "                        mapped_label = most_frequent_label\n",
        "\n",
        "                        segmented_data.append(segment)\n",
        "                        segmented_labels.append(mapped_label)\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                else:\n",
        "                     continue\n",
        "else:\n",
        "    print(\"Downsampled data or chest signal not found.\")\n",
        "\n",
        "\n",
        "print(f\"Total segments created: {len(segmented_data)}\")\n",
        "print(f\"Total labels created: {len(segmented_labels)}\")\n",
        "\n",
        "# Combine segmented_data and segmented_labels\n",
        "\n",
        "segmented_data_np = np.array(segmented_data)\n",
        "segmented_labels_np = np.array(segmented_labels)\n",
        "\n",
        "print(\"\\nSegmentation and labeling complete.\")\n",
        "print(f\"Shape of segmented data array: {segmented_data_np.shape}\")\n",
        "print(f\"Shape of segmented labels array: {segmented_labels_np.shape}\")\n",
        "\n",
        "# Print the multi-class labels\n",
        "unique_labels, counts = np.unique(segmented_labels_np, return_counts=True)\n",
        "print(\"\\nDistribution of multi-class labels:\")\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Label {label}: {count} segments\")\n",
        "\n",
        "# Check for null values in the labels\n",
        "null_labels_count = np.isnan(segmented_labels_np).sum()\n",
        "print(f\"\\nNumber of null values in segmented labels: {null_labels_count}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total segments created: 367\n",
            "Total labels created: 367\n",
            "\n",
            "Segmentation and labeling complete.\n",
            "Shape of segmented data array: (367, 3000, 1)\n",
            "Shape of segmented labels array: (367,)\n",
            "\n",
            "Distribution of multi-class labels:\n",
            "Label 0: 141 segments\n",
            "Label 1: 102 segments\n",
            "Label 2: 46 segments\n",
            "Label 3: 26 segments\n",
            "Label 4: 52 segments\n",
            "\n",
            "Number of null values in segmented labels: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7350ca98"
      },
      "source": [
        "### Edit feature extraction so that each is accounted for"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad169466",
        "outputId": "f05e2a6a-f3f9-40b5-99f6-a75f988c4e5f"
      },
      "source": [
        "import neurokit2 as nk\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.ndimage import uniform_filter1d\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "##Extract EDA features: mean, variance, tonic level, phasic peak counts.\n",
        "def extract_eda_features_basic(eda_segment, sampling_rate=4):\n",
        "    features = {}\n",
        "    if eda_segment.ndim > 1:\n",
        "        eda_segment = eda_segment.flatten()\n",
        "\n",
        "    features['eda_mean'] = np.mean(eda_segment)\n",
        "    features['eda_variance'] = np.var(eda_segment)\n",
        "\n",
        "    # Smoothing data for tonic/phasic\n",
        "    tonic = uniform_filter1d(eda_segment, size=int(sampling_rate*5)) # Smoothing over 5 seconds\n",
        "    phasic = eda_segment - tonic\n",
        "\n",
        "    features['eda_tonic'] = np.mean(tonic)\n",
        "\n",
        "    # Find phasic peaks\n",
        "    peaks, _ = find_peaks(phasic, height=np.std(phasic)*0.1)\n",
        "    features['eda_phasic_peak_counts'] = len(peaks)\n",
        "\n",
        "    return features\n",
        "\n",
        "##Extract ECG features: mean, variance, and a simple measure of variability.\n",
        "def extract_ecg_features_basic(ecg_segment, sampling_rate=4):\n",
        "    features = {}\n",
        "    if ecg_segment.ndim > 1:\n",
        "        ecg_segment = ecg_segment.flatten()\n",
        "\n",
        "    features['ecg_mean'] = np.mean(ecg_segment)\n",
        "    features['ecg_variance'] = np.var(ecg_segment)\n",
        "    features['ecg_std'] = np.std(ecg_segment)\n",
        "\n",
        "    return features\n",
        "\n",
        "##Extract Respiration features: mean, variance, and amplitude.\n",
        "def extract_respiration_features_basic(resp_segment, sampling_rate=4):\n",
        "    features = {}\n",
        "    if resp_segment.ndim > 1:\n",
        "        resp_segment = resp_segment.flatten()\n",
        "\n",
        "    features['resp_mean'] = np.mean(resp_segment)\n",
        "    features['resp_variance'] = np.var(resp_segment)\n",
        "    features['resp_amplitude_std'] = np.std(resp_segment)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Redefining from previous steps\n",
        "window_size = 60  # In seconds\n",
        "overlap = 0.5 # For 50% overlap\n",
        "desired_sampling_rate = 4 # In Hz\n",
        "\n",
        "# Step 2: Calculate window size again\n",
        "window_samples = int(window_size * desired_sampling_rate)\n",
        "step_samples = int(window_samples * (1 - overlap))\n",
        "\n",
        "# Initialize dictionaries to store segmented data and labels per sensor type\n",
        "segmented_data_by_sensor = {\n",
        "    'ECG': [],\n",
        "    'Resp': [],\n",
        "    'EDA': []\n",
        "}\n",
        "segmented_labels_by_sensor = {\n",
        "    'ECG': [],\n",
        "    'Resp': [],\n",
        "    'EDA': []\n",
        "}\n",
        "\n",
        "# Step 3: Re-segment data and store by sensor type\n",
        "relevant_signals = {\n",
        "    'chest': ['ECG', 'Resp', 'EDA']\n",
        "}\n",
        "\n",
        "if 'signal' in downsampled_data and 'chest' in downsampled_data['signal']:\n",
        "    for sensor in relevant_signals['chest']:\n",
        "        if sensor in downsampled_data['signal']['chest'] and isinstance(downsampled_data['signal']['chest'][sensor], np.ndarray):\n",
        "            sensor_data = downsampled_data['signal']['chest'][sensor]\n",
        "            label_data = downsampled_data['label']\n",
        "\n",
        "            num_samples = sensor_data.shape[0]\n",
        "\n",
        "            # Iterate through data with the sliding window\n",
        "            for start_sample in range(0, num_samples - window_samples + 1, step_samples):\n",
        "                end_sample = start_sample + window_samples\n",
        "\n",
        "                # Segment the sensor data\n",
        "                segment = sensor_data[start_sample:end_sample]\n",
        "\n",
        "                # Assign label to the segment based on the most frequent label in the original data window\n",
        "                original_chest_sampling_rate = 700\n",
        "                downsampling_factor_chest = original_chest_sampling_rate / desired_sampling_rate\n",
        "\n",
        "                original_start_sample = int(start_sample * downsampling_factor_chest)\n",
        "                original_end_sample = int(end_sample * downsampling_factor_chest)\n",
        "\n",
        "                original_end_sample = min(original_end_sample, len(label_data))\n",
        "                original_start_sample = min(original_start_sample, original_end_sample)\n",
        "\n",
        "                segment_labels_original = label_data[original_start_sample:original_end_sample]\n",
        "\n",
        "                if len(segment_labels_original) > 0:\n",
        "                    unique_labels, counts = np.unique(segment_labels_original, return_counts=True)\n",
        "                    most_frequent_label = unique_labels[np.argmax(counts)]\n",
        "\n",
        "                    # Assign multi-class labels (0-4), ignore 5, 6, 7\n",
        "                    if most_frequent_label in [0, 1, 2, 3, 4]:\n",
        "                        mapped_label = most_frequent_label\n",
        "                        segmented_data_by_sensor[sensor].append(segment)\n",
        "                        segmented_labels_by_sensor[sensor].append(mapped_label)\n",
        "\n",
        "else:\n",
        "    print(\"Downsampled data or chest signal not found.\")\n",
        "\n",
        "\n",
        "print(\"Segmentation by sensor type complete.\")\n",
        "for sensor, segments in segmented_data_by_sensor.items():\n",
        "    print(f\"  {sensor}: {len(segments)} segments\")\n",
        "    if len(segments) > 0:\n",
        "        print(f\"    Sample segment shape: {segments[0].shape}\")\n",
        "\n",
        "\n",
        "# Step 4: Extract features for each segment by sensor type\n",
        "extracted_features_by_sensor = {\n",
        "    'ECG': [],\n",
        "    'Resp': [],\n",
        "    'EDA': []\n",
        "}\n",
        "\n",
        "print(\"\\nExtracting features by sensor type...\")\n",
        "for sensor, segments in segmented_data_by_sensor.items():\n",
        "    print(f\"  Extracting features for {sensor} segments...\")\n",
        "    for segment in segments:\n",
        "        try:\n",
        "            if sensor == 'ECG':\n",
        "                features = extract_ecg_features_basic(segment, sampling_rate=desired_sampling_rate)\n",
        "            elif sensor == 'Resp':\n",
        "                features = extract_respiration_features_basic(segment, sampling_rate=desired_sampling_rate)\n",
        "            elif sensor == 'EDA':\n",
        "                features = extract_eda_features_basic(segment, sampling_rate=desired_sampling_rate)\n",
        "            else:\n",
        "                features = {}\n",
        "\n",
        "            extracted_features_by_sensor[sensor].append(features)\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting features for {sensor} segment: {e}\")\n",
        "\n",
        "            if sensor == 'ECG':\n",
        "                 extracted_features_by_sensor[sensor].append({\n",
        "                    'ecg_mean': np.nan,\n",
        "                    'ecg_variance': np.nan,\n",
        "                    'ecg_std': np.nan\n",
        "                 })\n",
        "            elif sensor == 'Resp':\n",
        "                 extracted_features_by_sensor[sensor].append({\n",
        "                    'resp_mean': np.nan,\n",
        "                    'resp_variance': np.nan,\n",
        "                    'resp_amplitude_std': np.nan\n",
        "                 })\n",
        "            elif sensor == 'EDA':\n",
        "                 extracted_features_by_sensor[sensor].append({\n",
        "                    'eda_mean': np.nan,\n",
        "                    'eda_variance': np.nan,\n",
        "                    'eda_tonic': np.nan,\n",
        "                    'eda_phasic_peak_counts': np.nan\n",
        "                 })\n",
        "\n",
        "\n",
        "# Step 5: Combine features from different sensors for the same time window\n",
        "\n",
        "num_segments_ecg = len(extracted_features_by_sensor['ECG'])\n",
        "num_segments_resp = len(extracted_features_by_sensor['Resp'])\n",
        "num_segments_eda = len(extracted_features_by_sensor['EDA'])\n",
        "\n",
        "if not (num_segments_ecg == num_segments_resp and num_segments_resp == num_segments_eda):\n",
        "    print(f\"\\nWarning: Number of segments for different sensors is not consistent (ECG: {num_segments_ecg}, Resp: {num_segments_resp}, EDA: {num_segments_eda}). Combining features might be inaccurate.\")\n",
        "    min_segments = min(num_segments_ecg, num_segments_resp, num_segments_eda)\n",
        "    print(f\"Proceeding by combining features for the minimum number of segments ({min_segments}). This might drop some segments.\")\n",
        "else:\n",
        "    min_segments = num_segments_ecg\n",
        "\n",
        "all_combined_features = []\n",
        "combined_labels = []\n",
        "\n",
        "print(\"\\nCombining features...\")\n",
        "for i in range(min_segments):\n",
        "    combined_feature_vector = {}\n",
        "\n",
        "    # Combine features from each sensor for the current time window\n",
        "    if i < num_segments_ecg:\n",
        "        combined_feature_vector.update(extracted_features_by_sensor['ECG'][i])\n",
        "        # label from the first sensor type's segment\n",
        "        if i < len(segmented_labels_by_sensor['ECG']):\n",
        "            current_label = segmented_labels_by_sensor['ECG'][i]\n",
        "        else:\n",
        "            current_label = np.nan # if label is missing\n",
        "\n",
        "    if i < num_segments_resp:\n",
        "        combined_feature_vector.update(extracted_features_by_sensor['Resp'][i])\n",
        "\n",
        "\n",
        "    if i < num_segments_eda:\n",
        "        combined_feature_vector.update(extracted_features_by_sensor['EDA'][i])\n",
        "\n",
        "\n",
        "    all_combined_features.append(combined_feature_vector)\n",
        "    combined_labels.append(current_label) # Use the label captured from the first sensor type\n",
        "\n",
        "\n",
        "print(f\"Total combined feature vectors created: {len(all_combined_features)}\")\n",
        "print(f\"Total combined labels created: {len(combined_labels)}\")\n",
        "\n",
        "# Step 6: Create DataFrame and add labels\n",
        "features_df = pd.DataFrame(all_combined_features)\n",
        "features_df['label'] = combined_labels\n",
        "\n",
        "print(\"\\nCombined Features DataFrame:\")\n",
        "display(features_df.head())\n",
        "print(f\"\\nShape of combined features DataFrame: {features_df.shape}\")\n",
        "\n",
        "# Step 7: Impute null values (if needed)\n",
        "print(\"\\nChecking for and imputing remaining null values...\")\n",
        "print(\"Null values before imputation:\")\n",
        "print(features_df.isnull().sum())\n",
        "\n",
        "# Impute null values with the mean of each column\n",
        "features_df.fillna(features_df.mean(), inplace=True)\n",
        "\n",
        "print(\"\\nNull values after imputation:\")\n",
        "print(features_df.isnull().sum())\n",
        "\n",
        "print(\"\\nFeatures DataFrame after imputation:\")\n",
        "display(features_df.head())\n",
        "\n",
        "print(\"\\nFeature Extraction and Combination Complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation by sensor type complete.\n",
            "  ECG: 171 segments\n",
            "    Sample segment shape: (240, 1)\n",
            "  Resp: 171 segments\n",
            "    Sample segment shape: (240, 1)\n",
            "  EDA: 171 segments\n",
            "    Sample segment shape: (240, 1)\n",
            "\n",
            "Extracting features by sensor type...\n",
            "  Extracting features for ECG segments...\n",
            "  Extracting features for Resp segments...\n",
            "  Extracting features for EDA segments...\n",
            "\n",
            "Combining features...\n",
            "Total combined feature vectors created: 171\n",
            "Total combined labels created: 171\n",
            "\n",
            "Combined Features DataFrame:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ecg_mean  ecg_variance   ecg_std  resp_mean  resp_variance  \\\n",
              "0  0.006460      0.089402  0.299001   0.160095       5.937844   \n",
              "1 -0.028707      0.081607  0.285669  -0.245070      14.131317   \n",
              "2  0.017170      0.132313  0.363748  -0.497213      11.102979   \n",
              "3  0.016961      0.068439  0.261609   0.490759       2.660999   \n",
              "4 -0.015815      0.068661  0.262032  -0.012261       3.140748   \n",
              "\n",
              "   resp_amplitude_std  eda_mean  eda_variance  eda_tonic  \\\n",
              "0            2.436769  1.365700      0.008231   1.365910   \n",
              "1            3.759164  1.371712      0.000042   1.371669   \n",
              "2            3.332113  1.381771      0.000034   1.381729   \n",
              "3            1.631257  1.393311      0.000065   1.393267   \n",
              "4            1.772216  1.402038      0.000033   1.402001   \n",
              "\n",
              "   eda_phasic_peak_counts  label  \n",
              "0                      12      0  \n",
              "1                      85      0  \n",
              "2                      70      0  \n",
              "3                      64      1  \n",
              "4                      66      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0d3599c-5649-47cb-8e33-1a7d87d080b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ecg_mean</th>\n",
              "      <th>ecg_variance</th>\n",
              "      <th>ecg_std</th>\n",
              "      <th>resp_mean</th>\n",
              "      <th>resp_variance</th>\n",
              "      <th>resp_amplitude_std</th>\n",
              "      <th>eda_mean</th>\n",
              "      <th>eda_variance</th>\n",
              "      <th>eda_tonic</th>\n",
              "      <th>eda_phasic_peak_counts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006460</td>\n",
              "      <td>0.089402</td>\n",
              "      <td>0.299001</td>\n",
              "      <td>0.160095</td>\n",
              "      <td>5.937844</td>\n",
              "      <td>2.436769</td>\n",
              "      <td>1.365700</td>\n",
              "      <td>0.008231</td>\n",
              "      <td>1.365910</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.028707</td>\n",
              "      <td>0.081607</td>\n",
              "      <td>0.285669</td>\n",
              "      <td>-0.245070</td>\n",
              "      <td>14.131317</td>\n",
              "      <td>3.759164</td>\n",
              "      <td>1.371712</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>1.371669</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.017170</td>\n",
              "      <td>0.132313</td>\n",
              "      <td>0.363748</td>\n",
              "      <td>-0.497213</td>\n",
              "      <td>11.102979</td>\n",
              "      <td>3.332113</td>\n",
              "      <td>1.381771</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>1.381729</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.016961</td>\n",
              "      <td>0.068439</td>\n",
              "      <td>0.261609</td>\n",
              "      <td>0.490759</td>\n",
              "      <td>2.660999</td>\n",
              "      <td>1.631257</td>\n",
              "      <td>1.393311</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>1.393267</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.015815</td>\n",
              "      <td>0.068661</td>\n",
              "      <td>0.262032</td>\n",
              "      <td>-0.012261</td>\n",
              "      <td>3.140748</td>\n",
              "      <td>1.772216</td>\n",
              "      <td>1.402038</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.402001</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0d3599c-5649-47cb-8e33-1a7d87d080b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0d3599c-5649-47cb-8e33-1a7d87d080b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0d3599c-5649-47cb-8e33-1a7d87d080b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cd0a6a97-7a4e-4ad1-9894-9bdff0b232fc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd0a6a97-7a4e-4ad1-9894-9bdff0b232fc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cd0a6a97-7a4e-4ad1-9894-9bdff0b232fc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nFeature Extraction and Combination Complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ecg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020587183033056865,\n        \"min\": -0.028706661667100196,\n        \"max\": 0.017170390470814256,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.028706661667100196,\n          -0.01581512274916176,\n          0.017170390470814256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02628228407657045,\n        \"min\": 0.06843936889858511,\n        \"max\": 0.13231260986056914,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.08160661263996784,\n          0.06866083757236613,\n          0.13231260986056914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04192096299262007,\n        \"min\": 0.26160919115846276,\n        \"max\": 0.3637480032392881,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.28566871134229566,\n          0.2620321308014842,\n          0.3637480032392881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3780724925058515,\n        \"min\": -0.49721320412241266,\n        \"max\": 0.4907592184317317,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.2450700575707644,\n          -0.012261476283907708,\n          -0.49721320412241266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.043803032631162,\n        \"min\": 2.6609992701675345,\n        \"max\": 14.13131705565989,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14.13131705565989,\n          3.1407483811876706,\n          11.102978814810532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_amplitude_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9392880673329007,\n        \"min\": 1.6312569601897595,\n        \"max\": 3.7591644092351015,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.7591644092351015,\n          1.772215670054768,\n          3.3321132656034567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014974490658147079,\n        \"min\": 1.3657003853273864,\n        \"max\": 1.4020383120273676,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3717119709010512,\n          1.4020383120273676,\n          1.381770989175402\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0036616117558870643,\n        \"min\": 3.296543634954292e-05,\n        \"max\": 0.008230893888678129,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.1536598790652306e-05,\n          3.296543634954292e-05,\n          3.3808739148708046e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_tonic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014903793493564634,\n        \"min\": 1.3659103347714387,\n        \"max\": 1.402001241841152,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3716685686488777,\n          1.402001241841152,\n          1.3817292105300174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_phasic_peak_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 12,\n        \"max\": 85,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          66,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of combined features DataFrame: (171, 11)\n",
            "\n",
            "Checking for and imputing remaining null values...\n",
            "Null values before imputation:\n",
            "ecg_mean                  0\n",
            "ecg_variance              0\n",
            "ecg_std                   0\n",
            "resp_mean                 0\n",
            "resp_variance             0\n",
            "resp_amplitude_std        0\n",
            "eda_mean                  0\n",
            "eda_variance              0\n",
            "eda_tonic                 0\n",
            "eda_phasic_peak_counts    0\n",
            "label                     0\n",
            "dtype: int64\n",
            "\n",
            "Null values after imputation:\n",
            "ecg_mean                  0\n",
            "ecg_variance              0\n",
            "ecg_std                   0\n",
            "resp_mean                 0\n",
            "resp_variance             0\n",
            "resp_amplitude_std        0\n",
            "eda_mean                  0\n",
            "eda_variance              0\n",
            "eda_tonic                 0\n",
            "eda_phasic_peak_counts    0\n",
            "label                     0\n",
            "dtype: int64\n",
            "\n",
            "Features DataFrame after imputation:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ecg_mean  ecg_variance   ecg_std  resp_mean  resp_variance  \\\n",
              "0  0.006460      0.089402  0.299001   0.160095       5.937844   \n",
              "1 -0.028707      0.081607  0.285669  -0.245070      14.131317   \n",
              "2  0.017170      0.132313  0.363748  -0.497213      11.102979   \n",
              "3  0.016961      0.068439  0.261609   0.490759       2.660999   \n",
              "4 -0.015815      0.068661  0.262032  -0.012261       3.140748   \n",
              "\n",
              "   resp_amplitude_std  eda_mean  eda_variance  eda_tonic  \\\n",
              "0            2.436769  1.365700      0.008231   1.365910   \n",
              "1            3.759164  1.371712      0.000042   1.371669   \n",
              "2            3.332113  1.381771      0.000034   1.381729   \n",
              "3            1.631257  1.393311      0.000065   1.393267   \n",
              "4            1.772216  1.402038      0.000033   1.402001   \n",
              "\n",
              "   eda_phasic_peak_counts  label  \n",
              "0                      12      0  \n",
              "1                      85      0  \n",
              "2                      70      0  \n",
              "3                      64      1  \n",
              "4                      66      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f735d9e0-5a7b-4135-bd1b-4cfedcb9316a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ecg_mean</th>\n",
              "      <th>ecg_variance</th>\n",
              "      <th>ecg_std</th>\n",
              "      <th>resp_mean</th>\n",
              "      <th>resp_variance</th>\n",
              "      <th>resp_amplitude_std</th>\n",
              "      <th>eda_mean</th>\n",
              "      <th>eda_variance</th>\n",
              "      <th>eda_tonic</th>\n",
              "      <th>eda_phasic_peak_counts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006460</td>\n",
              "      <td>0.089402</td>\n",
              "      <td>0.299001</td>\n",
              "      <td>0.160095</td>\n",
              "      <td>5.937844</td>\n",
              "      <td>2.436769</td>\n",
              "      <td>1.365700</td>\n",
              "      <td>0.008231</td>\n",
              "      <td>1.365910</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.028707</td>\n",
              "      <td>0.081607</td>\n",
              "      <td>0.285669</td>\n",
              "      <td>-0.245070</td>\n",
              "      <td>14.131317</td>\n",
              "      <td>3.759164</td>\n",
              "      <td>1.371712</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>1.371669</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.017170</td>\n",
              "      <td>0.132313</td>\n",
              "      <td>0.363748</td>\n",
              "      <td>-0.497213</td>\n",
              "      <td>11.102979</td>\n",
              "      <td>3.332113</td>\n",
              "      <td>1.381771</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>1.381729</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.016961</td>\n",
              "      <td>0.068439</td>\n",
              "      <td>0.261609</td>\n",
              "      <td>0.490759</td>\n",
              "      <td>2.660999</td>\n",
              "      <td>1.631257</td>\n",
              "      <td>1.393311</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>1.393267</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.015815</td>\n",
              "      <td>0.068661</td>\n",
              "      <td>0.262032</td>\n",
              "      <td>-0.012261</td>\n",
              "      <td>3.140748</td>\n",
              "      <td>1.772216</td>\n",
              "      <td>1.402038</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.402001</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f735d9e0-5a7b-4135-bd1b-4cfedcb9316a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f735d9e0-5a7b-4135-bd1b-4cfedcb9316a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f735d9e0-5a7b-4135-bd1b-4cfedcb9316a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-69bde1a2-6b22-47e1-aee5-322c50253621\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69bde1a2-6b22-47e1-aee5-322c50253621')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-69bde1a2-6b22-47e1-aee5-322c50253621 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nFeature Extraction and Combination Complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ecg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020587183033056865,\n        \"min\": -0.028706661667100196,\n        \"max\": 0.017170390470814256,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.028706661667100196,\n          -0.01581512274916176,\n          0.017170390470814256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02628228407657045,\n        \"min\": 0.06843936889858511,\n        \"max\": 0.13231260986056914,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.08160661263996784,\n          0.06866083757236613,\n          0.13231260986056914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04192096299262007,\n        \"min\": 0.26160919115846276,\n        \"max\": 0.3637480032392881,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.28566871134229566,\n          0.2620321308014842,\n          0.3637480032392881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3780724925058515,\n        \"min\": -0.49721320412241266,\n        \"max\": 0.4907592184317317,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.2450700575707644,\n          -0.012261476283907708,\n          -0.49721320412241266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.043803032631162,\n        \"min\": 2.6609992701675345,\n        \"max\": 14.13131705565989,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14.13131705565989,\n          3.1407483811876706,\n          11.102978814810532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_amplitude_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9392880673329007,\n        \"min\": 1.6312569601897595,\n        \"max\": 3.7591644092351015,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.7591644092351015,\n          1.772215670054768,\n          3.3321132656034567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014974490658147079,\n        \"min\": 1.3657003853273864,\n        \"max\": 1.4020383120273676,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3717119709010512,\n          1.4020383120273676,\n          1.381770989175402\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0036616117558870643,\n        \"min\": 3.296543634954292e-05,\n        \"max\": 0.008230893888678129,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.1536598790652306e-05,\n          3.296543634954292e-05,\n          3.3808739148708046e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_tonic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014903793493564634,\n        \"min\": 1.3659103347714387,\n        \"max\": 1.402001241841152,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3716685686488777,\n          1.402001241841152,\n          1.3817292105300174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_phasic_peak_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 12,\n        \"max\": 85,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          66,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Extraction and Combination Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44b068c3"
      },
      "source": [
        "## Begin feature extraction\n",
        "\n",
        "### Only applying feature extraction to chest data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fe10d04",
        "outputId": "c59ff771-9894-41bd-c4a1-4c1321182127",
        "collapsed": true
      },
      "source": [
        "import neurokit2 as nk\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.ndimage import uniform_filter1d\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "##Extract EDA features: mean, variance, tonic level, phasic peak counts.\n",
        "def extract_eda_features_basic(eda_segment, sampling_rate=4):\n",
        "    features = {}\n",
        "    if eda_segment.ndim > 1:\n",
        "        eda_segment = eda_segment.flatten()\n",
        "\n",
        "    features['eda_mean'] = np.mean(eda_segment)\n",
        "    features['eda_variance'] = np.var(eda_segment)\n",
        "\n",
        "    # Smoothing data for tonic/phasic\n",
        "    tonic = uniform_filter1d(eda_segment, size=int(sampling_rate*5)) # Smoothing over 5 seconds\n",
        "    phasic = eda_segment - tonic\n",
        "\n",
        "    features['eda_tonic'] = np.mean(tonic)\n",
        "\n",
        "    # Find phasic peaks\n",
        "    peaks, _ = find_peaks(phasic, height=np.std(phasic)*0.1)\n",
        "    features['eda_phasic_peak_counts'] = len(peaks)\n",
        "\n",
        "    return features\n",
        "\n",
        "##Extract ECG features: mean, variance, and a simple measure of variability.\n",
        "def extract_ecg_features_basic(ecg_segment, sampling_rate=4):\n",
        "    features = {}\n",
        "    if ecg_segment.ndim > 1:\n",
        "        ecg_segment = ecg_segment.flatten()\n",
        "\n",
        "    features['ecg_mean'] = np.mean(ecg_segment)\n",
        "    features['ecg_variance'] = np.var(ecg_segment)\n",
        "    features['ecg_std'] = np.std(ecg_segment)\n",
        "\n",
        "    return features\n",
        "\n",
        "##Extract Respiration features: mean, variance, and amplitude.\n",
        "def extract_respiration_features_basic(resp_segment, sampling_rate=4):\n",
        "    features = {}\n",
        "    if resp_segment.ndim > 1:\n",
        "        resp_segment = resp_segment.flatten()\n",
        "\n",
        "    features['resp_mean'] = np.mean(resp_segment)\n",
        "    features['resp_variance'] = np.var(resp_segment)\n",
        "    features['resp_amplitude_std'] = np.std(resp_segment)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Ensure segmented_data_by_sensor and segmented_labels_by_sensor are defined\n",
        "# (They should be populated by the preceding data segmentation step (cell 9abc93cf))\n",
        "if 'segmented_data_by_sensor' not in globals() or 'segmented_labels_by_sensor' not in globals():\n",
        "    print(\"Warning: 'segmented_data_by_sensor' or 'segmented_labels_by_sensor' not found. \"\n",
        "          \"Please ensure the data segmentation cell (9abc93cf) has been executed.\")\n",
        "    segmented_data_by_sensor = {'ECG': [], 'Resp': [], 'EDA': []}\n",
        "    segmented_labels_by_sensor = {'ECG': [], 'Resp': [], 'EDA': []}\n",
        "\n",
        "\n",
        "# Extract features for chest ECG segments\n",
        "ecg_segments = segmented_data_by_sensor.get('ECG', [])\n",
        "print(f\"Extracting basic features for {len(ecg_segments)} chest ECG segments...\")\n",
        "ecg_features = []\n",
        "for i, segment in enumerate(ecg_segments):\n",
        "    try:\n",
        "        features = extract_ecg_features_basic(segment, sampling_rate=desired_sampling_rate)\n",
        "        ecg_features.append(features)\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting chest ECG basic features for segment {i}: {e}\")\n",
        "        ecg_features.append({\n",
        "            'ecg_mean': np.nan,\n",
        "            'ecg_variance': np.nan,\n",
        "            'ecg_std': np.nan\n",
        "        })\n",
        "\n",
        "# Extract features for chest Respiration segments\n",
        "resp_segments = segmented_data_by_sensor.get('Resp', [])\n",
        "print(f\"Extracting basic features for {len(resp_segments)} chest Respiration segments...\")\n",
        "resp_features = []\n",
        "for i, segment in enumerate(resp_segments):\n",
        "    try:\n",
        "        features = extract_respiration_features_basic(segment, sampling_rate=desired_sampling_rate)\n",
        "        resp_features.append(features)\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting chest Respiration basic features for segment {i}: {e}\")\n",
        "        resp_features.append({\n",
        "            'resp_mean': np.nan,\n",
        "            'resp_variance': np.nan,\n",
        "            'resp_amplitude_std': np.nan\n",
        "        })\n",
        "\n",
        "# Extract features for chest EDA segments\n",
        "eda_segments = segmented_data_by_sensor.get('EDA', [])\n",
        "print(f\"Extracting basic features for {len(eda_segments)} chest EDA segments...\")\n",
        "eda_features = []\n",
        "for i, segment in enumerate(eda_segments):\n",
        "    try:\n",
        "        features = extract_eda_features_basic(segment, sampling_rate=desired_sampling_rate)\n",
        "        eda_features.append(features)\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting chest EDA basic features for segment {i}: {e}\")\n",
        "        eda_features.append({\n",
        "            'eda_mean': np.nan,\n",
        "            'eda_variance': np.nan,\n",
        "            'eda_tonic': np.nan,\n",
        "            'eda_phasic_peak_counts': np.nan\n",
        "        })\n",
        "\n",
        "\n",
        "# Combine features from different sensors based on the minimum number of segments\n",
        "min_segments = min(len(ecg_features), len(resp_features), len(eda_features))\n",
        "all_features = []\n",
        "for i in range(min_segments):\n",
        "    combined_feature_vector = {}\n",
        "    combined_feature_vector.update(ecg_features[i])\n",
        "    combined_feature_vector.update(resp_features[i])\n",
        "    combined_feature_vector.update(eda_features[i])\n",
        "    all_features.append(combined_feature_vector)\n",
        "\n",
        "\n",
        "print(f\"Total features extracted: {len(all_features)}\")\n",
        "\n",
        "# Convert the list of dictionaries to a pandas DataFrame\n",
        "features_df = pd.DataFrame(all_features)\n",
        "\n",
        "print(\"\\nBasic Feature Extraction Complete.\")\n",
        "display(features_df.head())\n",
        "print(f\"\\nShape of features DataFrame: {features_df.shape}\")\n",
        "\n",
        "# Add the labels to the DataFrame - ensure labels match the number of combined features\n",
        "# Check if segmented_labels_by_sensor['ECG'] is not empty before attempting to slice\n",
        "if segmented_labels_by_sensor.get('ECG') and len(segmented_labels_by_sensor['ECG']) >= len(features_df):\n",
        "    features_df['label'] = segmented_labels_by_sensor['ECG'][:len(features_df)]\n",
        "else:\n",
        "    print(\"Warning: Labels for features_df could not be assigned, likely due to missing or insufficient segmented_labels_by_sensor['ECG'] data.\")\n",
        "    features_df['label'] = np.nan # Assign NaN or a placeholder if labels are unavailable\n",
        "\n",
        "\n",
        "print(\"\\nFeatures DataFrame with labels:\")\n",
        "display(features_df.head())\n",
        "print(f\"\\nShape of features DataFrame with labels: {features_df.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting basic features for 171 chest ECG segments...\n",
            "Extracting basic features for 171 chest Respiration segments...\n",
            "Extracting basic features for 171 chest EDA segments...\n",
            "Total features extracted: 171\n",
            "\n",
            "Basic Feature Extraction Complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ecg_mean  ecg_variance   ecg_std  resp_mean  resp_variance  \\\n",
              "0  0.006460      0.089402  0.299001   0.160095       5.937844   \n",
              "1 -0.028707      0.081607  0.285669  -0.245070      14.131317   \n",
              "2  0.017170      0.132313  0.363748  -0.497213      11.102979   \n",
              "3  0.016961      0.068439  0.261609   0.490759       2.660999   \n",
              "4 -0.015815      0.068661  0.262032  -0.012261       3.140748   \n",
              "\n",
              "   resp_amplitude_std  eda_mean  eda_variance  eda_tonic  \\\n",
              "0            2.436769  1.365700      0.008231   1.365910   \n",
              "1            3.759164  1.371712      0.000042   1.371669   \n",
              "2            3.332113  1.381771      0.000034   1.381729   \n",
              "3            1.631257  1.393311      0.000065   1.393267   \n",
              "4            1.772216  1.402038      0.000033   1.402001   \n",
              "\n",
              "   eda_phasic_peak_counts  \n",
              "0                      12  \n",
              "1                      85  \n",
              "2                      70  \n",
              "3                      64  \n",
              "4                      66  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-618c4d26-10ea-4bed-a157-c7ed88353f6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ecg_mean</th>\n",
              "      <th>ecg_variance</th>\n",
              "      <th>ecg_std</th>\n",
              "      <th>resp_mean</th>\n",
              "      <th>resp_variance</th>\n",
              "      <th>resp_amplitude_std</th>\n",
              "      <th>eda_mean</th>\n",
              "      <th>eda_variance</th>\n",
              "      <th>eda_tonic</th>\n",
              "      <th>eda_phasic_peak_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006460</td>\n",
              "      <td>0.089402</td>\n",
              "      <td>0.299001</td>\n",
              "      <td>0.160095</td>\n",
              "      <td>5.937844</td>\n",
              "      <td>2.436769</td>\n",
              "      <td>1.365700</td>\n",
              "      <td>0.008231</td>\n",
              "      <td>1.365910</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.028707</td>\n",
              "      <td>0.081607</td>\n",
              "      <td>0.285669</td>\n",
              "      <td>-0.245070</td>\n",
              "      <td>14.131317</td>\n",
              "      <td>3.759164</td>\n",
              "      <td>1.371712</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>1.371669</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.017170</td>\n",
              "      <td>0.132313</td>\n",
              "      <td>0.363748</td>\n",
              "      <td>-0.497213</td>\n",
              "      <td>11.102979</td>\n",
              "      <td>3.332113</td>\n",
              "      <td>1.381771</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>1.381729</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.016961</td>\n",
              "      <td>0.068439</td>\n",
              "      <td>0.261609</td>\n",
              "      <td>0.490759</td>\n",
              "      <td>2.660999</td>\n",
              "      <td>1.631257</td>\n",
              "      <td>1.393311</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>1.393267</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.015815</td>\n",
              "      <td>0.068661</td>\n",
              "      <td>0.262032</td>\n",
              "      <td>-0.012261</td>\n",
              "      <td>3.140748</td>\n",
              "      <td>1.772216</td>\n",
              "      <td>1.402038</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.402001</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-618c4d26-10ea-4bed-a157-c7ed88353f6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-618c4d26-10ea-4bed-a157-c7ed88353f6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-618c4d26-10ea-4bed-a157-c7ed88353f6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-61077da2-eac2-473d-9f46-400c5c0a39f4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-61077da2-eac2-473d-9f46-400c5c0a39f4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-61077da2-eac2-473d-9f46-400c5c0a39f4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"\\\\nShape of features DataFrame with labels: {features_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ecg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020587183033056865,\n        \"min\": -0.028706661667100196,\n        \"max\": 0.017170390470814256,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.028706661667100196,\n          -0.01581512274916176,\n          0.017170390470814256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02628228407657045,\n        \"min\": 0.06843936889858511,\n        \"max\": 0.13231260986056914,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.08160661263996784,\n          0.06866083757236613,\n          0.13231260986056914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04192096299262007,\n        \"min\": 0.26160919115846276,\n        \"max\": 0.3637480032392881,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.28566871134229566,\n          0.2620321308014842,\n          0.3637480032392881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3780724925058515,\n        \"min\": -0.49721320412241266,\n        \"max\": 0.4907592184317317,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.2450700575707644,\n          -0.012261476283907708,\n          -0.49721320412241266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.043803032631162,\n        \"min\": 2.6609992701675345,\n        \"max\": 14.13131705565989,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14.13131705565989,\n          3.1407483811876706,\n          11.102978814810532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_amplitude_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9392880673329007,\n        \"min\": 1.6312569601897595,\n        \"max\": 3.7591644092351015,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.7591644092351015,\n          1.772215670054768,\n          3.3321132656034567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014974490658147079,\n        \"min\": 1.3657003853273864,\n        \"max\": 1.4020383120273676,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3717119709010512,\n          1.4020383120273676,\n          1.381770989175402\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0036616117558870643,\n        \"min\": 3.296543634954292e-05,\n        \"max\": 0.008230893888678129,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.1536598790652306e-05,\n          3.296543634954292e-05,\n          3.3808739148708046e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_tonic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014903793493564634,\n        \"min\": 1.3659103347714387,\n        \"max\": 1.402001241841152,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3716685686488777,\n          1.402001241841152,\n          1.3817292105300174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_phasic_peak_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 12,\n        \"max\": 85,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          66,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of features DataFrame: (171, 10)\n",
            "\n",
            "Features DataFrame with labels:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ecg_mean  ecg_variance   ecg_std  resp_mean  resp_variance  \\\n",
              "0  0.006460      0.089402  0.299001   0.160095       5.937844   \n",
              "1 -0.028707      0.081607  0.285669  -0.245070      14.131317   \n",
              "2  0.017170      0.132313  0.363748  -0.497213      11.102979   \n",
              "3  0.016961      0.068439  0.261609   0.490759       2.660999   \n",
              "4 -0.015815      0.068661  0.262032  -0.012261       3.140748   \n",
              "\n",
              "   resp_amplitude_std  eda_mean  eda_variance  eda_tonic  \\\n",
              "0            2.436769  1.365700      0.008231   1.365910   \n",
              "1            3.759164  1.371712      0.000042   1.371669   \n",
              "2            3.332113  1.381771      0.000034   1.381729   \n",
              "3            1.631257  1.393311      0.000065   1.393267   \n",
              "4            1.772216  1.402038      0.000033   1.402001   \n",
              "\n",
              "   eda_phasic_peak_counts  label  \n",
              "0                      12      0  \n",
              "1                      85      0  \n",
              "2                      70      0  \n",
              "3                      64      1  \n",
              "4                      66      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3991e18e-60ad-493e-b7fa-ae67b64c622c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ecg_mean</th>\n",
              "      <th>ecg_variance</th>\n",
              "      <th>ecg_std</th>\n",
              "      <th>resp_mean</th>\n",
              "      <th>resp_variance</th>\n",
              "      <th>resp_amplitude_std</th>\n",
              "      <th>eda_mean</th>\n",
              "      <th>eda_variance</th>\n",
              "      <th>eda_tonic</th>\n",
              "      <th>eda_phasic_peak_counts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006460</td>\n",
              "      <td>0.089402</td>\n",
              "      <td>0.299001</td>\n",
              "      <td>0.160095</td>\n",
              "      <td>5.937844</td>\n",
              "      <td>2.436769</td>\n",
              "      <td>1.365700</td>\n",
              "      <td>0.008231</td>\n",
              "      <td>1.365910</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.028707</td>\n",
              "      <td>0.081607</td>\n",
              "      <td>0.285669</td>\n",
              "      <td>-0.245070</td>\n",
              "      <td>14.131317</td>\n",
              "      <td>3.759164</td>\n",
              "      <td>1.371712</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>1.371669</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.017170</td>\n",
              "      <td>0.132313</td>\n",
              "      <td>0.363748</td>\n",
              "      <td>-0.497213</td>\n",
              "      <td>11.102979</td>\n",
              "      <td>3.332113</td>\n",
              "      <td>1.381771</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>1.381729</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.016961</td>\n",
              "      <td>0.068439</td>\n",
              "      <td>0.261609</td>\n",
              "      <td>0.490759</td>\n",
              "      <td>2.660999</td>\n",
              "      <td>1.631257</td>\n",
              "      <td>1.393311</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>1.393267</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.015815</td>\n",
              "      <td>0.068661</td>\n",
              "      <td>0.262032</td>\n",
              "      <td>-0.012261</td>\n",
              "      <td>3.140748</td>\n",
              "      <td>1.772216</td>\n",
              "      <td>1.402038</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.402001</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3991e18e-60ad-493e-b7fa-ae67b64c622c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3991e18e-60ad-493e-b7fa-ae67b64c622c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3991e18e-60ad-493e-b7fa-ae67b64c622c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d7bb8418-f347-425a-a700-ff8389e4bcbc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7bb8418-f347-425a-a700-ff8389e4bcbc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d7bb8418-f347-425a-a700-ff8389e4bcbc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"\\\\nShape of features DataFrame with labels: {features_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ecg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020587183033056865,\n        \"min\": -0.028706661667100196,\n        \"max\": 0.017170390470814256,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.028706661667100196,\n          -0.01581512274916176,\n          0.017170390470814256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02628228407657045,\n        \"min\": 0.06843936889858511,\n        \"max\": 0.13231260986056914,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.08160661263996784,\n          0.06866083757236613,\n          0.13231260986056914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04192096299262007,\n        \"min\": 0.26160919115846276,\n        \"max\": 0.3637480032392881,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.28566871134229566,\n          0.2620321308014842,\n          0.3637480032392881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3780724925058515,\n        \"min\": -0.49721320412241266,\n        \"max\": 0.4907592184317317,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.2450700575707644,\n          -0.012261476283907708,\n          -0.49721320412241266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.043803032631162,\n        \"min\": 2.6609992701675345,\n        \"max\": 14.13131705565989,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14.13131705565989,\n          3.1407483811876706,\n          11.102978814810532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_amplitude_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9392880673329007,\n        \"min\": 1.6312569601897595,\n        \"max\": 3.7591644092351015,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.7591644092351015,\n          1.772215670054768,\n          3.3321132656034567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014974490658147079,\n        \"min\": 1.3657003853273864,\n        \"max\": 1.4020383120273676,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3717119709010512,\n          1.4020383120273676,\n          1.381770989175402\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0036616117558870643,\n        \"min\": 3.296543634954292e-05,\n        \"max\": 0.008230893888678129,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.1536598790652306e-05,\n          3.296543634954292e-05,\n          3.3808739148708046e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_tonic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014903793493564634,\n        \"min\": 1.3659103347714387,\n        \"max\": 1.402001241841152,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3716685686488777,\n          1.402001241841152,\n          1.3817292105300174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_phasic_peak_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 12,\n        \"max\": 85,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          66,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of features DataFrame with labels: (171, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Show examples of extracted features"
      ],
      "metadata": {
        "id": "HpQl7uwujCeN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b42e5085",
        "outputId": "47c8ed58-699d-4c5e-89da-238bd4c7de33"
      },
      "source": [
        "# Filter the DataFrame to show rows where the label is not 0\n",
        "non_zero_labels_df = features_df[features_df['label'] != 0]\n",
        "\n",
        "# Display the first few rows of the filtered DataFrame\n",
        "print(\"Examples of extracted features for segments with labels other than 0:\")\n",
        "if not non_zero_labels_df.empty:\n",
        "    display(non_zero_labels_df.head())\n",
        "else:\n",
        "    print(\"No segments found with labels other than 0 in the features_df DataFrame.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples of extracted features for segments with labels other than 0:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ecg_mean  ecg_variance   ecg_std  resp_mean  resp_variance  \\\n",
              "3  0.016961      0.068439  0.261609   0.490759       2.660999   \n",
              "4 -0.015815      0.068661  0.262032  -0.012261       3.140748   \n",
              "5 -0.006031      0.132337  0.363782  -0.326114      10.571401   \n",
              "6  0.012194      0.074609  0.273147   1.101551      19.432121   \n",
              "7 -0.003071      0.073347  0.270827   0.229675      30.833342   \n",
              "\n",
              "   resp_amplitude_std  eda_mean  eda_variance  eda_tonic  \\\n",
              "3            1.631257  1.393311      0.000065   1.393267   \n",
              "4            1.772216  1.402038      0.000033   1.402001   \n",
              "5            3.251369  1.408200      0.000037   1.408175   \n",
              "6            4.408188  1.418376      0.000044   1.418339   \n",
              "7            5.552778  1.430399      0.000050   1.430351   \n",
              "\n",
              "   eda_phasic_peak_counts  label  \n",
              "3                      64      1  \n",
              "4                      66      1  \n",
              "5                      64      1  \n",
              "6                      52      1  \n",
              "7                      59      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60b7365e-6e20-411f-a7ac-893a47fe1b5b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ecg_mean</th>\n",
              "      <th>ecg_variance</th>\n",
              "      <th>ecg_std</th>\n",
              "      <th>resp_mean</th>\n",
              "      <th>resp_variance</th>\n",
              "      <th>resp_amplitude_std</th>\n",
              "      <th>eda_mean</th>\n",
              "      <th>eda_variance</th>\n",
              "      <th>eda_tonic</th>\n",
              "      <th>eda_phasic_peak_counts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.016961</td>\n",
              "      <td>0.068439</td>\n",
              "      <td>0.261609</td>\n",
              "      <td>0.490759</td>\n",
              "      <td>2.660999</td>\n",
              "      <td>1.631257</td>\n",
              "      <td>1.393311</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>1.393267</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.015815</td>\n",
              "      <td>0.068661</td>\n",
              "      <td>0.262032</td>\n",
              "      <td>-0.012261</td>\n",
              "      <td>3.140748</td>\n",
              "      <td>1.772216</td>\n",
              "      <td>1.402038</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.402001</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.006031</td>\n",
              "      <td>0.132337</td>\n",
              "      <td>0.363782</td>\n",
              "      <td>-0.326114</td>\n",
              "      <td>10.571401</td>\n",
              "      <td>3.251369</td>\n",
              "      <td>1.408200</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>1.408175</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.012194</td>\n",
              "      <td>0.074609</td>\n",
              "      <td>0.273147</td>\n",
              "      <td>1.101551</td>\n",
              "      <td>19.432121</td>\n",
              "      <td>4.408188</td>\n",
              "      <td>1.418376</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>1.418339</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.003071</td>\n",
              "      <td>0.073347</td>\n",
              "      <td>0.270827</td>\n",
              "      <td>0.229675</td>\n",
              "      <td>30.833342</td>\n",
              "      <td>5.552778</td>\n",
              "      <td>1.430399</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>1.430351</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60b7365e-6e20-411f-a7ac-893a47fe1b5b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60b7365e-6e20-411f-a7ac-893a47fe1b5b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60b7365e-6e20-411f-a7ac-893a47fe1b5b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5cfe7343-74c7-4e2c-89f2-576a6d18ffdb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5cfe7343-74c7-4e2c-89f2-576a6d18ffdb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5cfe7343-74c7-4e2c-89f2-576a6d18ffdb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"No segments found with labels other than 0 in the features_df DataFrame\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ecg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013497215475503548,\n        \"min\": -0.01581512274916176,\n        \"max\": 0.016960965208188735,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.01581512274916176,\n          -0.0030707560757208966,\n          -0.006030792749193727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02745095481849324,\n        \"min\": 0.06843936889858511,\n        \"max\": 0.13233717356738553,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.06866083757236613,\n          0.07334712318827957,\n          0.13233717356738553\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04363032113474964,\n        \"min\": 0.26160919115846276,\n        \"max\": 0.36378176640313564,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2620321308014842,\n          0.27082674016477687,\n          0.36378176640313564\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5415928660024351,\n        \"min\": -0.3261143432604056,\n        \"max\": 1.1015509885927792,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.012261476283907708,\n          0.22967509179015563,\n          -0.3261143432604056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.925404880906758,\n        \"min\": 2.6609992701675345,\n        \"max\": 30.83334184091257,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.1407483811876706,\n          30.83334184091257,\n          10.571400887459715\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_amplitude_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6897928561470792,\n        \"min\": 1.6312569601897595,\n        \"max\": 5.552777849051101,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.772215670054768,\n          5.552777849051101,\n          3.251369078935782\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014407837298511526,\n        \"min\": 1.3933112105559535,\n        \"max\": 1.430398974772513,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.4020383120273676,\n          1.430398974772513,\n          1.4082003852259561\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2544363776649482e-05,\n        \"min\": 3.296543634954292e-05,\n        \"max\": 6.501870234391647e-05,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.296543634954292e-05,\n          4.969411943104932e-05,\n          3.7057333010528984e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_tonic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014405777052841412,\n        \"min\": 1.393266843329854,\n        \"max\": 1.4303512115316919,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.402001241841152,\n          1.4303512115316919,\n          1.4081748179701867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_phasic_peak_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 52,\n        \"max\": 66,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          66,\n          59,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2R_HSpNkdUHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Models\n",
        "\n",
        "* Logistic Regression\n",
        "* Random Forest Classifier\n",
        "* XGBoost"
      ],
      "metadata": {
        "id": "4UNgJGibdsfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Features on Baseline Models\n"
      ],
      "metadata": {
        "id": "WSVuaD5PjFK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression Model\n"
      ],
      "metadata": {
        "id": "VrrPcvgHkPTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'features_df' is your DataFrame with basic features and 'label' column\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = features_df.drop('label', axis=1)\n",
        "y = features_df['label']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# Check if there are enough samples for splitting\n",
        "if len(X) > 1:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    # Initialize and train the Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "else:\n",
        "    print(\"Not enough data to train the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urx9RVy9jR-u",
        "outputId": "b36dfe6e-12b3-4e41-c08b-2940939585ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5714285714285714\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.86      0.62        14\n",
            "           1       0.80      1.00      0.89         8\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.57        35\n",
            "   macro avg       0.26      0.37      0.30        35\n",
            "weighted avg       0.37      0.57      0.45        35\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[12  2  0  0  0]\n",
            " [ 0  8  0  0  0]\n",
            " [ 5  0  0  0  0]\n",
            " [ 3  0  0  0  0]\n",
            " [ 5  0  0  0  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest Classifier\n"
      ],
      "metadata": {
        "id": "_DhUZBcskTn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'features_df' is available from previous steps\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = features_df.drop('label', axis=1)\n",
        "y = features_df['label']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# Check if there are enough samples for splitting\n",
        "if len(X) > 1:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    # Initialize and train the Random Forest model\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "else:\n",
        "     print(\"Not enough data to train the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hqaT1FkkXIr",
        "outputId": "9a959e6d-ebd6-48bd-e145-411d6694f8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.64      0.72        14\n",
            "           1       0.80      1.00      0.89         8\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       0.50      0.60      0.55         5\n",
            "\n",
            "    accuracy                           0.80        35\n",
            "   macro avg       0.82      0.85      0.83        35\n",
            "weighted avg       0.81      0.80      0.80        35\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[9 2 0 0 3]\n",
            " [0 8 0 0 0]\n",
            " [0 0 5 0 0]\n",
            " [0 0 0 3 0]\n",
            " [2 0 0 0 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBoost Model"
      ],
      "metadata": {
        "id": "yaqd-1L0Yw9Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0077b6d1",
        "outputId": "61638160-c87a-414e-d11d-147ac85cecdd",
        "collapsed": true
      },
      "source": [
        "# Display the first few rows of the features_df DataFrame to show examples of the extracted features.\n",
        "if 'features_df' in locals():\n",
        "    print(\"Displaying the first 5 rows of the features_df DataFrame:\")\n",
        "    display(features_df.head())\n",
        "else:\n",
        "    print(\"The 'features_df' DataFrame is not available. Please run the data processing and feature extraction steps first.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying the first 5 rows of the features_df DataFrame:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ecg_mean  ecg_variance   ecg_std  resp_mean  resp_variance  \\\n",
              "0  0.006460      0.089402  0.299001   0.160095       5.937844   \n",
              "1 -0.028707      0.081607  0.285669  -0.245070      14.131317   \n",
              "2  0.017170      0.132313  0.363748  -0.497213      11.102979   \n",
              "3  0.016961      0.068439  0.261609   0.490759       2.660999   \n",
              "4 -0.015815      0.068661  0.262032  -0.012261       3.140748   \n",
              "\n",
              "   resp_amplitude_std  eda_mean  eda_variance  eda_tonic  \\\n",
              "0            2.436769  1.365700      0.008231   1.365910   \n",
              "1            3.759164  1.371712      0.000042   1.371669   \n",
              "2            3.332113  1.381771      0.000034   1.381729   \n",
              "3            1.631257  1.393311      0.000065   1.393267   \n",
              "4            1.772216  1.402038      0.000033   1.402001   \n",
              "\n",
              "   eda_phasic_peak_counts  label  \n",
              "0                      12      0  \n",
              "1                      85      0  \n",
              "2                      70      0  \n",
              "3                      64      1  \n",
              "4                      66      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-246fab5c-f60b-4083-8fcb-d5a035bf4348\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ecg_mean</th>\n",
              "      <th>ecg_variance</th>\n",
              "      <th>ecg_std</th>\n",
              "      <th>resp_mean</th>\n",
              "      <th>resp_variance</th>\n",
              "      <th>resp_amplitude_std</th>\n",
              "      <th>eda_mean</th>\n",
              "      <th>eda_variance</th>\n",
              "      <th>eda_tonic</th>\n",
              "      <th>eda_phasic_peak_counts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006460</td>\n",
              "      <td>0.089402</td>\n",
              "      <td>0.299001</td>\n",
              "      <td>0.160095</td>\n",
              "      <td>5.937844</td>\n",
              "      <td>2.436769</td>\n",
              "      <td>1.365700</td>\n",
              "      <td>0.008231</td>\n",
              "      <td>1.365910</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.028707</td>\n",
              "      <td>0.081607</td>\n",
              "      <td>0.285669</td>\n",
              "      <td>-0.245070</td>\n",
              "      <td>14.131317</td>\n",
              "      <td>3.759164</td>\n",
              "      <td>1.371712</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>1.371669</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.017170</td>\n",
              "      <td>0.132313</td>\n",
              "      <td>0.363748</td>\n",
              "      <td>-0.497213</td>\n",
              "      <td>11.102979</td>\n",
              "      <td>3.332113</td>\n",
              "      <td>1.381771</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>1.381729</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.016961</td>\n",
              "      <td>0.068439</td>\n",
              "      <td>0.261609</td>\n",
              "      <td>0.490759</td>\n",
              "      <td>2.660999</td>\n",
              "      <td>1.631257</td>\n",
              "      <td>1.393311</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>1.393267</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.015815</td>\n",
              "      <td>0.068661</td>\n",
              "      <td>0.262032</td>\n",
              "      <td>-0.012261</td>\n",
              "      <td>3.140748</td>\n",
              "      <td>1.772216</td>\n",
              "      <td>1.402038</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.402001</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-246fab5c-f60b-4083-8fcb-d5a035bf4348')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-246fab5c-f60b-4083-8fcb-d5a035bf4348 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-246fab5c-f60b-4083-8fcb-d5a035bf4348');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4d8b3e6f-011b-49ac-a439-4d6259237236\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d8b3e6f-011b-49ac-a439-4d6259237236')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4d8b3e6f-011b-49ac-a439-4d6259237236 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"The 'features_df' DataFrame is not available\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ecg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020587183033056865,\n        \"min\": -0.028706661667100196,\n        \"max\": 0.017170390470814256,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.028706661667100196,\n          -0.01581512274916176,\n          0.017170390470814256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02628228407657045,\n        \"min\": 0.06843936889858511,\n        \"max\": 0.13231260986056914,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.08160661263996784,\n          0.06866083757236613,\n          0.13231260986056914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecg_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04192096299262007,\n        \"min\": 0.26160919115846276,\n        \"max\": 0.3637480032392881,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.28566871134229566,\n          0.2620321308014842,\n          0.3637480032392881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3780724925058515,\n        \"min\": -0.49721320412241266,\n        \"max\": 0.4907592184317317,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.2450700575707644,\n          -0.012261476283907708,\n          -0.49721320412241266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.043803032631162,\n        \"min\": 2.6609992701675345,\n        \"max\": 14.13131705565989,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14.13131705565989,\n          3.1407483811876706,\n          11.102978814810532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resp_amplitude_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9392880673329007,\n        \"min\": 1.6312569601897595,\n        \"max\": 3.7591644092351015,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.7591644092351015,\n          1.772215670054768,\n          3.3321132656034567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014974490658147079,\n        \"min\": 1.3657003853273864,\n        \"max\": 1.4020383120273676,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3717119709010512,\n          1.4020383120273676,\n          1.381770989175402\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_variance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0036616117558870643,\n        \"min\": 3.296543634954292e-05,\n        \"max\": 0.008230893888678129,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.1536598790652306e-05,\n          3.296543634954292e-05,\n          3.3808739148708046e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_tonic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014903793493564634,\n        \"min\": 1.3659103347714387,\n        \"max\": 1.402001241841152,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.3716685686488777,\n          1.402001241841152,\n          1.3817292105300174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_phasic_peak_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 12,\n        \"max\": 85,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          66,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02d17abb",
        "outputId": "77615133-8990-4174-cee5-70ae98e96815"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = features_df.drop('label', axis=1)\n",
        "y = features_df['label']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "if len(X) > 1:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    # train the XGBoost model\n",
        "    model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(y.unique()), eval_metric='mlogloss', use_label_encoder=False, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make prediction on the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "else:\n",
        "     print(\"Not enough data - try again.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92        14\n",
            "           1       0.80      1.00      0.89         8\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.94        35\n",
            "   macro avg       0.96      0.97      0.96        35\n",
            "weighted avg       0.95      0.94      0.94        35\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[12  2  0  0  0]\n",
            " [ 0  8  0  0  0]\n",
            " [ 0  0  5  0  0]\n",
            " [ 0  0  0  3  0]\n",
            " [ 0  0  0  0  5]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [01:10:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load & consolidate WESAD data for neural network"
      ],
      "metadata": {
        "id": "wsSuEKUOBDtn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cd0103f",
        "outputId": "4b1eb7c3-c372-43e0-99f7-7cb980a0e9d0"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# 1. Initialize an empty list to store all subjects' data\n",
        "all_subjects_data = []\n",
        "\n",
        "# Define the directory containing WESAD subject folders\n",
        "wesad_dir = '/content/data/WESAD/'\n",
        "subject_dirs = glob.glob(os.path.join(wesad_dir, 'S*'))\n",
        "\n",
        "# 2. Iterate through each subject directory\n",
        "for subject_dir in subject_dirs:\n",
        "    # 3. Construct the full path to the .pkl file for the current subject\n",
        "    pkl_files = glob.glob(os.path.join(subject_dir, '*.pkl'))\n",
        "    if pkl_files:\n",
        "        subject_file = pkl_files[0]\n",
        "\n",
        "        try:\n",
        "            # 4. Open and load each .pkl file\n",
        "            with open(subject_file, 'rb') as f:\n",
        "                data = pickle.load(f, encoding='latin1')\n",
        "\n",
        "            # 5. Extract 'chest' signals and 'label' array\n",
        "            chest_signals = data['signal']['chest']\n",
        "            labels = data['label']\n",
        "\n",
        "            # 6. Store extracted data and append to the list\n",
        "            all_subjects_data.append({\n",
        "                'chest_signals': chest_signals,\n",
        "                'labels': labels\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading or processing {subject_file}: {e}\")\n",
        "\n",
        "# 7. Print total data loaded and display details of first few rows\n",
        "print(f\"Total subjects successfully loaded: {len(all_subjects_data)}\")\n",
        "\n",
        "if all_subjects_data:\n",
        "    first_subject = all_subjects_data[0]\n",
        "    print(\"\\nDetails for the first loaded subject:\")\n",
        "    print(f\"  Keys of chest_signals: {first_subject['chest_signals'].keys()}\")\n",
        "    print(f\"  Shape of labels array: {first_subject['labels'].shape}\")\n",
        "else:\n",
        "    print(\"No subjects were loaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total subjects successfully loaded: 15\n",
            "\n",
            "Details for the first loaded subject:\n",
            "  Keys of chest_signals: dict_keys(['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'])\n",
            "  Shape of labels array: (3676400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eee14292"
      },
      "source": [
        "### Downsample and Segment Subjects' Data\n",
        "\n",
        "#### Details:\n",
        "Process the data by applying desired downsampling rates for ECG, EDA, and Respiration signals. Then, segment each downsampled signal into 60-second windows with 50% overlap. Assign multi-class labels (0-4) to each segment based on the most frequent original label within that window.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cc3a7913",
        "outputId": "629edcba-309b-4ab0-8272-e7c953bac40d"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.signal import resample\n",
        "\n",
        "# 1. Initialize empty dictionaries to store segmented data and labels from all subjects\n",
        "all_segmented_data_by_sensor = {\n",
        "    'ECG': [],\n",
        "    'Resp': [],\n",
        "    'EDA': []\n",
        "}\n",
        "all_segmented_labels_by_sensor = {\n",
        "    'ECG': [],\n",
        "    'Resp': [],\n",
        "    'EDA': []\n",
        "}\n",
        "\n",
        "# 2. Define the target downsampling rates and original sampling rate\n",
        "ecg_target_sampling_rate = 125  # Hz\n",
        "eda_target_sampling_rate = 4  # Hz\n",
        "resp_target_sampling_rate = 25  # Hz\n",
        "original_chest_sampling_rate = 700 # Hz for all chest sensors in original data\n",
        "\n",
        "# 3. Define segmentation parameters\n",
        "window_size = 30  # In seconds\n",
        "overlap = 0.5     # For 50% overlap\n",
        "\n",
        "# 4. Iterate through each subject_data dictionary in the all_subjects_data list\n",
        "for subject_idx, subject_data in enumerate(all_subjects_data):\n",
        "    print(f\"Processing subject {subject_idx + 1}/{len(all_subjects_data)}...\")\n",
        "    current_chest_signals = subject_data['chest_signals']\n",
        "    original_labels = subject_data['labels']\n",
        "\n",
        "    subject_downsampled_data = {'chest': {}}\n",
        "\n",
        "    # 4.c. Downsample each sensor signal for the current subject\n",
        "    for sensor_name, sensor_data_array in current_chest_signals.items():\n",
        "        if not isinstance(sensor_data_array, np.ndarray):\n",
        "            # print(f\"  Skipping non-array data for sensor {sensor_name}\")\n",
        "            continue\n",
        "\n",
        "        num_original_samples = sensor_data_array.shape[0]\n",
        "        current_original_sampling_rate = original_chest_sampling_rate # All chest sensors start at 700 Hz\n",
        "\n",
        "        target_sampling_rate = current_original_sampling_rate # Default to original if not specified for segmentation\n",
        "\n",
        "        if sensor_name == 'ECG':\n",
        "            target_sampling_rate = ecg_target_sampling_rate\n",
        "        elif sensor_name == 'EDA':\n",
        "            target_sampling_rate = eda_target_sampling_rate\n",
        "        elif sensor_name == 'Resp':\n",
        "            target_sampling_rate = resp_target_sampling_rate\n",
        "        # For 'ACC', 'EMG', 'Temp', target_sampling_rate remains current_original_sampling_rate (700 Hz)\n",
        "\n",
        "        num_desired_samples = int(num_original_samples * (target_sampling_rate / current_original_sampling_rate))\n",
        "\n",
        "        if num_desired_samples == 0:\n",
        "            # print(f\"  Warning: Downsampled {sensor_name} would have 0 samples, skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Resample each column if it's multi-dimensional (e.g., ACC) or a single column\n",
        "        if sensor_data_array.ndim > 1:\n",
        "            downsampled_sensor_data = np.zeros((num_desired_samples, sensor_data_array.shape[1]))\n",
        "            for col in range(sensor_data_array.shape[1]):\n",
        "                downsampled_sensor_data[:, col] = resample(sensor_data_array[:, col], num_desired_samples)\n",
        "        else:\n",
        "            downsampled_sensor_data = resample(sensor_data_array, num_desired_samples)\n",
        "\n",
        "        subject_downsampled_data['chest'][sensor_name] = downsampled_sensor_data\n",
        "\n",
        "    # 4.d. Segment relevant sensors and assign labels for the current subject\n",
        "    relevant_sensors_for_segmentation = ['ECG', 'Resp', 'EDA']\n",
        "    for sensor_to_segment in relevant_sensors_for_segmentation:\n",
        "        if sensor_to_segment not in subject_downsampled_data['chest']:\n",
        "            print(f\"  Warning: {sensor_to_segment} data not available for segmentation for this subject.\")\n",
        "            continue\n",
        "\n",
        "        downsampled_sensor_data = subject_downsampled_data['chest'][sensor_to_segment]\n",
        "        num_downsampled_samples = downsampled_sensor_data.shape[0]\n",
        "\n",
        "        # Determine the effective sampling rate for this sensor to calculate window_samples\n",
        "        current_segmentation_sampling_rate = 0\n",
        "        if sensor_to_segment == 'ECG':\n",
        "            current_segmentation_sampling_rate = ecg_target_sampling_rate\n",
        "        elif sensor_to_segment == 'EDA':\n",
        "            current_segmentation_sampling_rate = eda_target_sampling_rate\n",
        "        elif sensor_to_segment == 'Resp':\n",
        "            current_segmentation_sampling_rate = resp_target_sampling_rate\n",
        "\n",
        "        if current_segmentation_sampling_rate == 0:\n",
        "            print(f\"  Error: Could not determine segmentation sampling rate for {sensor_to_segment}. Skipping segmentation.\")\n",
        "            continue\n",
        "\n",
        "        # Calculate window and step size in samples based on the sensor's desired sampling rate\n",
        "        current_window_samples = int(window_size * current_segmentation_sampling_rate)\n",
        "        current_step_samples = int(current_window_samples * (1 - overlap))\n",
        "\n",
        "        if current_window_samples == 0 or current_step_samples == 0:\n",
        "            print(f\"  Warning: Window or step size for {sensor_to_segment} is zero, skipping segmentation.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        for start_sample_downsampled in range(0, num_downsampled_samples - current_window_samples + 1, current_step_samples):\n",
        "            end_sample_downsampled = start_sample_downsampled + current_window_samples\n",
        "\n",
        "            segment = downsampled_sensor_data[start_sample_downsampled:end_sample_downsampled]\n",
        "\n",
        "            # Map downsampled segment indices back to original label indices\n",
        "            sampling_rate_ratio = original_chest_sampling_rate / current_segmentation_sampling_rate\n",
        "\n",
        "            original_start_sample_for_label = int(start_sample_downsampled * sampling_rate_ratio)\n",
        "            original_end_sample_for_label = int(end_sample_downsampled * sampling_rate_ratio)\n",
        "\n",
        "            # Ensure original_end_sample_for_label does not exceed original_labels length\n",
        "            original_end_sample_for_label = min(original_end_sample_for_label, len(original_labels))\n",
        "            original_start_sample_for_label = min(original_start_sample_for_label, original_end_sample_for_label) # Ensure start is not after end\n",
        "\n",
        "            if original_start_sample_for_label >= original_end_sample_for_label:\n",
        "                continue # Skip if no valid range for labels\n",
        "\n",
        "            segment_labels_original = original_labels[original_start_sample_for_label:original_end_sample_for_label]\n",
        "\n",
        "            # Assign label based on the most frequent among 0-4, ignoring 5, 6, 7\n",
        "            valid_labels = segment_labels_original[(segment_labels_original >= 0) & (segment_labels_original <= 4)]\n",
        "\n",
        "            if len(valid_labels) > 0:\n",
        "                unique_labels, counts = np.unique(valid_labels, return_counts=True)\n",
        "                most_frequent_label = unique_labels[np.argmax(counts)]\n",
        "\n",
        "                all_segmented_data_by_sensor[sensor_to_segment].append(segment)\n",
        "                all_segmented_labels_by_sensor[sensor_to_segment].append(most_frequent_label)\n",
        "            else:\n",
        "                # If no valid labels (0-4) are found, skip this segment\n",
        "                continue\n",
        "\n",
        "print(\"\\n--- All Subjects Processing Complete ---\")\n",
        "\n",
        "# 5. Print the total number of segments created for each sensor type\n",
        "print(\"\\nTotal segments created per sensor type:\")\n",
        "for sensor, segments_list in all_segmented_data_by_sensor.items():\n",
        "    print(f\"  {sensor}: {len(segments_list)} segments\")\n",
        "    if len(segments_list) > 0:\n",
        "        print(f\"    Sample segment shape: {segments_list[0].shape}\")\n",
        "\n",
        "# 6. Print the distribution of multi-class labels across all combined segments\n",
        "print(\"\\nDistribution of multi-class labels across all combined segments:\")\n",
        "all_labels_combined_for_report = []\n",
        "for sensor in relevant_sensors_for_segmentation:\n",
        "    all_labels_combined_for_report.extend(all_segmented_labels_by_sensor[sensor])\n",
        "\n",
        "if len(all_labels_combined_for_report) > 0:\n",
        "    unique_labels, counts = np.unique(all_labels_combined_for_report, return_counts=True)\n",
        "    for label, count in zip(unique_labels, counts):\n",
        "        print(f\"  Label {label}: {count} segments\")\n",
        "else:\n",
        "    print(\"  No segments with valid labels were created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 1/15...\n",
            "Processing subject 2/15...\n",
            "Processing subject 3/15...\n",
            "Processing subject 4/15...\n",
            "Processing subject 5/15...\n",
            "Processing subject 6/15...\n",
            "Processing subject 7/15...\n",
            "Processing subject 8/15...\n",
            "Processing subject 9/15...\n",
            "Processing subject 10/15...\n",
            "Processing subject 11/15...\n",
            "Processing subject 12/15...\n",
            "Processing subject 13/15...\n",
            "Processing subject 14/15...\n",
            "Processing subject 15/15...\n",
            "\n",
            "--- All Subjects Processing Complete ---\n",
            "\n",
            "Total segments created per sensor type:\n",
            "  ECG: 5701 segments\n",
            "    Sample segment shape: (3750, 1)\n",
            "  Resp: 5701 segments\n",
            "    Sample segment shape: (750, 1)\n",
            "  EDA: 5701 segments\n",
            "    Sample segment shape: (120, 1)\n",
            "\n",
            "Distribution of multi-class labels across all combined segments:\n",
            "  Label 0: 8115 segments\n",
            "  Label 1: 3519 segments\n",
            "  Label 2: 2001 segments\n",
            "  Label 3: 1113 segments\n",
            "  Label 4: 2355 segments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Baseline"
      ],
      "metadata": {
        "id": "BRitx224d-Wh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "618dc9f4"
      },
      "source": [
        "## Prepare Neural Network Data\n",
        "\n",
        "### Details:\n",
        "Extract and combine the segmented signal data (ECG, Respiration, and EDA) from `segmented_data_by_sensor`. Standardize the signal data using `StandardScaler` and reshape for the 1D-CNN input. Finally, split the combined dataset into training, validation, and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4aa0fa7",
        "outputId": "f90ad449-f65a-47b8-96bf-347945afd333"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Convert segmented data to NumPy arrays\n",
        "X_ecg = np.array(all_segmented_data_by_sensor['ECG'])\n",
        "X_resp = np.array(all_segmented_data_by_sensor['Resp'])\n",
        "X_eda = np.array(all_segmented_data_by_sensor['EDA'])\n",
        "\n",
        "# Ensure all arrays have the same number of segments\n",
        "min_segments = min(X_ecg.shape[0], X_resp.shape[0], X_eda.shape[0])\n",
        "X_ecg = X_ecg[:min_segments]\n",
        "X_resp = X_resp[:min_segments]\n",
        "X_eda = X_eda[:min_segments]\n",
        "# Create y labels\n",
        "y_labels = np.array(all_segmented_labels_by_sensor['ECG']) # Assuming labels are consistent across sensors\n",
        "y_labels = y_labels[:min_segments]\n",
        "\n",
        "\n",
        "# ECG Standardization\n",
        "num_segments_ecg, sequence_length_ecg, num_features_ecg = X_ecg.shape\n",
        "scaler_ecg = StandardScaler()\n",
        "X_ecg_scaled = scaler_ecg.fit_transform(X_ecg.reshape(-1, num_features_ecg)).reshape(num_segments_ecg, sequence_length_ecg, num_features_ecg)\n",
        "\n",
        "# Respiration Standardization\n",
        "num_segments_resp, sequence_length_resp, num_features_resp = X_resp.shape\n",
        "scaler_resp = StandardScaler()\n",
        "X_resp_scaled = scaler_resp.fit_transform(X_resp.reshape(-1, num_features_resp)).reshape(num_segments_resp, sequence_length_resp, num_features_resp)\n",
        "\n",
        "# EDA Standardization\n",
        "num_segments_eda, sequence_length_eda, num_features_eda = X_eda.shape\n",
        "scaler_eda = StandardScaler()\n",
        "X_eda_scaled = scaler_eda.fit_transform(X_eda.reshape(-1, num_features_eda)).reshape(num_segments_eda, sequence_length_eda, num_features_eda)\n",
        "\n",
        "\n",
        "# Split into training and temporary sets (40% train, 60% temp to reduce training data)\n",
        "X_train_ecg, X_temp_ecg, X_train_resp, X_temp_resp, X_train_eda, X_temp_eda, y_train, y_temp = train_test_split(\n",
        "    X_ecg_scaled, X_resp_scaled, X_eda_scaled, y_labels,\n",
        "    test_size=0.6, random_state=42, stratify=y_labels\n",
        ")\n",
        "\n",
        "# Split the temporary set into validation and test sets (50% val, 50% test of temp set)\n",
        "X_val_ecg, X_test_ecg, X_val_resp, X_test_resp, X_val_eda, X_test_eda, y_val, y_test = train_test_split(\n",
        "    X_temp_ecg, X_temp_resp, X_temp_eda, y_temp,\n",
        "    test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Print/QA sizes of the datasets\n",
        "print(f\"Size of X_train_ecg: {X_train_ecg.shape}\")\n",
        "print(f\"Size of X_train_resp: {X_train_resp.shape}\")\n",
        "print(f\"Size of X_train_eda: {X_train_eda.shape}\")\n",
        "print(f\"Size of y_train: {y_train.shape}\")\n",
        "print(f\"Size of X_val_ecg: {X_val_ecg.shape}\")\n",
        "print(f\"Size of X_val_resp: {X_val_resp.shape}\")\n",
        "print(f\"Size of X_val_eda: {X_val_eda.shape}\")\n",
        "print(f\"Size of y_val: {y_val.shape}\")\n",
        "print(f\"Size of X_test_ecg: {X_test_ecg.shape}\")\n",
        "print(f\"Size of X_test_resp: {X_test_resp.shape}\")\n",
        "print(f\"Size of X_test_eda: {X_test_eda.shape}\")\n",
        "print(f\"Size of y_test: {y_test.shape}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X_train_ecg: (2280, 3750, 1)\n",
            "Size of X_train_resp: (2280, 750, 1)\n",
            "Size of X_train_eda: (2280, 120, 1)\n",
            "Size of y_train: (2280,)\n",
            "Size of X_val_ecg: (1710, 3750, 1)\n",
            "Size of X_val_resp: (1710, 750, 1)\n",
            "Size of X_val_eda: (1710, 120, 1)\n",
            "Size of y_val: (1710,)\n",
            "Size of X_test_ecg: (1711, 3750, 1)\n",
            "Size of X_test_resp: (1711, 750, 1)\n",
            "Size of X_test_eda: (1711, 120, 1)\n",
            "Size of y_test: (1711,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d89a0494"
      },
      "source": [
        "## Build 1D-CNN + BiLSTM Model Architecture\n",
        "\n",
        "### Details:\n",
        "Construct the neural network model. The architecture will include separate 1D-CNN layers for each modality (ECG, Respiration, EDA) to capture local patterns. The output of each 1D-CNN branch will then be fed into BiLSTM layers to capture temporal dependencies. A fusion layer will concatenate the outputs from the BiLSTM layers. The model will conclude with fully connected layers and a softmax activation function for multi-class classification (stress/non-stress)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0e67b45",
        "outputId": "6f446d0f-a5a8-477c-c559-35f853dbd0f7"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, concatenate, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "#1 Define input shape for each modality\n",
        "sequence_length_ecg = X_train_ecg.shape[1]\n",
        "sequence_length_resp = X_train_resp.shape[1]\n",
        "sequence_length_eda = X_train_eda.shape[1]\n",
        "\n",
        "input_shape_ecg = (sequence_length_ecg, 1)\n",
        "input_shape_resp = (sequence_length_resp, 1)\n",
        "input_shape_eda = (sequence_length_eda, 1)\n",
        "\n",
        "#2 Create three separate Input layers\n",
        "ecg_input = Input(shape=input_shape_ecg, name='ecg_input')\n",
        "resp_input = Input(shape=input_shape_resp, name='resp_input')\n",
        "eda_input = Input(shape=input_shape_eda, name='eda_input')\n",
        "\n",
        "#3 Build 1D-CNN branch for ECG (reduced filters to 32)\n",
        "ecg_branch = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(ecg_input)\n",
        "ecg_branch = MaxPooling1D(pool_size=2, padding='same')(ecg_branch)\n",
        "\n",
        "#4 Build 1D-CNN branch for Respiratory (reduced filters to 32)\n",
        "resp_branch = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(resp_input)\n",
        "resp_branch = MaxPooling1D(pool_size=2, padding='same')(resp_branch)\n",
        "\n",
        "#5 Build 1D-CNN branch for EDA (reduced filters to 32)\n",
        "eda_branch = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(eda_input)\n",
        "eda_branch = MaxPooling1D(pool_size=2, padding='same')(eda_branch)\n",
        "\n",
        "#6 Pass the output of each 1D-CNN branch through a Bidirectional(LSTM) layer (reduced LSTM units to 32)\n",
        "ecg_bilstm = Bidirectional(LSTM(32, return_sequences=False))(ecg_branch)\n",
        "resp_bilstm = Bidirectional(LSTM(32, return_sequences=False))(resp_branch)\n",
        "eda_bilstm = Bidirectional(LSTM(32, return_sequences=False))(eda_branch)\n",
        "\n",
        "#7 Concatenate the outputs of the three layers\n",
        "fused_output = concatenate([ecg_bilstm, resp_bilstm, eda_bilstm], axis=-1)\n",
        "dense_layer = Dense(128, activation='relu')(fused_output)\n",
        "\n",
        "#8 Create the final output\n",
        "num_classes = len(np.unique(y_train))\n",
        "output_layer = Dense(num_classes, activation='softmax')(dense_layer)\n",
        "\n",
        "#10 Instantiate the Keras Model\n",
        "model = Model(inputs=[ecg_input, resp_input, eda_input], outputs=output_layer)\n",
        "\n",
        "print(\"Model architecture defined successfully.\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model architecture defined successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ ecg_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3750\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ resp_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m750\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ eda_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3750\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │        \u001b[38;5;34m128\u001b[0m │ ecg_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m750\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ resp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ eda_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1875\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,640\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,640\u001b[0m │ max_pooling1d_4[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,640\u001b[0m │ max_pooling1d_5[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_3[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_4[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ bidirectional_5[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m645\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ ecg_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3750</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ resp_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ eda_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3750</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ ecg_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ resp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ eda_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1875</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ max_pooling1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ max_pooling1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m75,653\u001b[0m (295.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">75,653</span> (295.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m75,653\u001b[0m (295.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">75,653</span> (295.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "633a8ea4"
      },
      "source": [
        "## Train Neural Network\n",
        "\n",
        "### Details:\n",
        "Use the Adam optimizer and `SparseCategoricalCrossentropy` as the loss function. Implement early stopping using `tf.keras.callbacks.EarlyStopping` to monitor the validation ROC-AUC score.\n",
        "\n",
        "**Reasoning**:\n",
        "Compile the neural network model with the key metrics and accuracy scores, then set up early stopping and train the model with the provided data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "242e1b33",
        "outputId": "dba80458-03ab-4bb5-b68f-2d0208557902"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 1. Compile the model\n",
        "# Assuming 'model' is already defined from the previous step\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 2. Create an EarlyStopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 3. Train the model\n",
        "history = model.fit(\n",
        "    [X_train_ecg, X_train_resp, X_train_eda],\n",
        "    y_train,\n",
        "    epochs=80,\n",
        "    batch_size=32,\n",
        "    validation_data=(\n",
        "        [X_val_ecg, X_val_resp, X_val_eda],\n",
        "        y_val\n",
        "    ),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "print(\"Model compiled and training initiated.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m 8/72\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 2s/step - accuracy: 0.3617 - loss: 1.5789"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1149674939.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# 3. Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mX_train_ecg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_resp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_eda\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60e89da0"
      },
      "source": [
        "**Reasoning**:\n",
        "Compile the neural network model with the specified optimizer, loss function, and metrics, then set up early stopping and train the model with the provided data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "443eab73"
      },
      "source": [
        "## Evaluate Model Performance\n",
        "\n",
        "### Details:\n",
        "Evaluate the trained neural network model on the test dataset. This involves calculating the loss and accuracy metrics to understand how well the model generalizes to new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37389b0"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the model has been compiled and trained, it's essential to evaluate its performance on the test dataset to determine its generalization ability. This code will use the `evaluate` method to get the test loss and accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b64a9e4c",
        "outputId": "b0f923a3-1309-4e3e-96fb-0230b62ee404"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(\n",
        "    [X_test_ecg, X_test_resp, X_test_eda],\n",
        "    y_test,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.9800\n",
            "Test Accuracy: 0.6096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dc781dc"
      },
      "source": [
        "## Evaluate Neural Network Performance\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained neural network model on the held-out test set. Report key metrics and display a confusion matrix to visualize the model's performance across different classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcaba58a",
        "outputId": "f5340021-1d5b-4eee-acba-5d9fcc966dc3"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_prob = model.predict([\n",
        "    X_test_ecg,\n",
        "    X_test_resp,\n",
        "    X_test_eda\n",
        "])\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Print the Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# Print the Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 314ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.72      0.68       812\n",
            "           1       0.52      0.60      0.56       352\n",
            "           2       0.60      0.33      0.43       200\n",
            "           3       0.27      0.04      0.06       111\n",
            "           4       0.67      0.75      0.71       236\n",
            "\n",
            "    accuracy                           0.61      1711\n",
            "   macro avg       0.54      0.49      0.49      1711\n",
            "weighted avg       0.59      0.61      0.59      1711\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[586 130  43   7  46]\n",
            " [115 211   0   3  23]\n",
            " [120  11  66   0   3]\n",
            " [ 58  34   1   4  14]\n",
            " [ 43  16   0   1 176]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final PINN Model"
      ],
      "metadata": {
        "id": "jKYVyBg4eG4S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c2c10cd"
      },
      "source": [
        "## Begin data preparation for PINN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "93fe97cb",
        "outputId": "dec0e7e0-dbf2-4c37-e1be-59a1cdc4e9e9"
      },
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Set up Kaggle API credentials as environment variables for the shell\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# Use the environment variables in the shell command\n",
        "!export KAGGLE_USERNAME=$KAGGLE_USERNAME && export KAGGLE_KEY=$KAGGLE_KEY && kaggle datasets download -d mohamedasem318/wesad-full-dataset -p /content/data --unzip\n",
        "\n",
        "# Now, inspect the contents of /content to find where WESAD data actually landed\n",
        "print(\"\\nContents of /content/ after download and unzip:\")\n",
        "!ls -F /content\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedasem318/wesad-full-dataset\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Downloading wesad-full-dataset.zip to /content/data\n",
            " 99% 2.42G/2.43G [00:17<00:00, 275MB/s]\n",
            "100% 2.43G/2.43G [00:17<00:00, 151MB/s]\n",
            "\n",
            "Contents of /content/ after download and unzip:\n",
            "data/  sample_data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3f86c62",
        "outputId": "0f8c3b90-10ec-4bb7-dcc2-2c126cc56d8b"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# 1. Initialize an empty list to store all subjects' data\n",
        "all_subjects_data = []\n",
        "\n",
        "# Define the directory containing WESAD subject folders\n",
        "wesad_dir = '/content/data/WESAD/'\n",
        "subject_dirs = glob.glob(os.path.join(wesad_dir, 'S*'))\n",
        "\n",
        "# 2. Iterate through each subject directory\n",
        "for subject_dir in subject_dirs:\n",
        "    # 3. Construct the full path to the .pkl file for the current subject\n",
        "    pkl_files = glob.glob(os.path.join(subject_dir, '*.pkl'))\n",
        "    if pkl_files:\n",
        "        subject_file = pkl_files[0]\n",
        "\n",
        "        try:\n",
        "            # 4. Open and load each .pkl file\n",
        "            with open(subject_file, 'rb') as f:\n",
        "                data = pickle.load(f, encoding='latin1')\n",
        "\n",
        "            # 5. Extract 'chest' signals and 'label' array\n",
        "            chest_signals = data['signal']['chest']\n",
        "            labels = data['label']\n",
        "\n",
        "            # 6. Store extracted data and append to the list\n",
        "            all_subjects_data.append({\n",
        "                'chest_signals': chest_signals,\n",
        "                'labels': labels\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading or processing {subject_file}: {e}\")\n",
        "\n",
        "# 7. Print total data loaded and display details of first few rows\n",
        "print(f\"Total subjects successfully loaded: {len(all_subjects_data)}\")\n",
        "\n",
        "if all_subjects_data:\n",
        "    first_subject = all_subjects_data[0]\n",
        "    print(\"\\nDetails for the first loaded subject:\")\n",
        "    print(f\"  Keys of chest_signals: {first_subject['chest_signals'].keys()}\")\n",
        "    print(f\"  Shape of labels array: {first_subject['labels'].shape}\")\n",
        "else:\n",
        "    print(\"No subjects were loaded.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total subjects successfully loaded: 15\n",
            "\n",
            "Details for the first loaded subject:\n",
            "  Keys of chest_signals: dict_keys(['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'])\n",
            "  Shape of labels array: (3676400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4a8cd2d3",
        "outputId": "28f287ba-fab2-41cd-9974-f7164501b06d"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.signal import resample\n",
        "\n",
        "# 1. Initialize empty dictionaries to store segmented data and labels from all subjects\n",
        "all_segmented_data_by_sensor = {\n",
        "    'ECG': [],\n",
        "    'Resp': [],\n",
        "    'EDA': []\n",
        "}\n",
        "all_segmented_labels_by_sensor = {\n",
        "    'ECG': [],\n",
        "    'Resp': [],\n",
        "    'EDA': []\n",
        "}\n",
        "\n",
        "# 2. Define the target downsampling rates and original sampling rate\n",
        "ecg_target_sampling_rate = 125  # Hz\n",
        "eda_target_sampling_rate = 4  # Hz\n",
        "resp_target_sampling_rate = 25  # Hz\n",
        "original_chest_sampling_rate = 700 # Hz for all chest sensors in original data\n",
        "\n",
        "# 3. Define segmentation parameters\n",
        "window_size = 30  # In seconds\n",
        "overlap = 0.5     # For 50% overlap\n",
        "\n",
        "# 4. Iterate through each subject_data dictionary in the all_subjects_data list\n",
        "for subject_idx, subject_data in enumerate(all_subjects_data):\n",
        "    print(f\"Processing subject {subject_idx + 1}/{len(all_subjects_data)}...\")\n",
        "    current_chest_signals = subject_data['chest_signals']\n",
        "    original_labels = subject_data['labels']\n",
        "\n",
        "    subject_downsampled_data = {'chest': {}}\n",
        "\n",
        "    # 4.c. Downsample each sensor signal for the current subject\n",
        "    for sensor_name, sensor_data_array in current_chest_signals.items():\n",
        "        if not isinstance(sensor_data_array, np.ndarray):\n",
        "            # print(f\"  Skipping non-array data for sensor {sensor_name}\")\n",
        "            continue\n",
        "\n",
        "        num_original_samples = sensor_data_array.shape[0]\n",
        "        current_original_sampling_rate = original_chest_sampling_rate # All chest sensors start at 700 Hz\n",
        "\n",
        "        target_sampling_rate = current_original_sampling_rate # Default to original if not specified for segmentation\n",
        "\n",
        "        if sensor_name == 'ECG':\n",
        "            target_sampling_rate = ecg_target_sampling_rate\n",
        "        elif sensor_name == 'EDA':\n",
        "            target_sampling_rate = eda_target_sampling_rate\n",
        "        elif sensor_name == 'Resp':\n",
        "            target_sampling_rate = resp_target_sampling_rate\n",
        "        # For 'ACC', 'EMG', 'Temp', target_sampling_rate remains current_original_sampling_rate (700 Hz)\n",
        "\n",
        "        num_desired_samples = int(num_original_samples * (target_sampling_rate / current_original_sampling_rate))\n",
        "\n",
        "        if num_desired_samples == 0:\n",
        "            # print(f\"  Warning: Downsampled {sensor_name} would have 0 samples, skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Resample each column if it's multi-dimensional (e.g., ACC) or a single column\n",
        "        if sensor_data_array.ndim > 1:\n",
        "            downsampled_sensor_data = np.zeros((num_desired_samples, sensor_data_array.shape[1]))\n",
        "            for col in range(sensor_data_array.shape[1]):\n",
        "                downsampled_sensor_data[:, col] = resample(sensor_data_array[:, col], num_desired_samples)\n",
        "        else:\n",
        "            downsampled_sensor_data = resample(sensor_data_array, num_desired_samples)\n",
        "\n",
        "        subject_downsampled_data['chest'][sensor_name] = downsampled_sensor_data\n",
        "\n",
        "    # 4.d. Segment relevant sensors and assign labels for the current subject\n",
        "    relevant_sensors_for_segmentation = ['ECG', 'Resp', 'EDA']\n",
        "    for sensor_to_segment in relevant_sensors_for_segmentation:\n",
        "        if sensor_to_segment not in subject_downsampled_data['chest']:\n",
        "            print(f\"  Warning: {sensor_to_segment} data not available for segmentation for this subject.\")\n",
        "            continue\n",
        "\n",
        "        downsampled_sensor_data = subject_downsampled_data['chest'][sensor_to_segment]\n",
        "        num_downsampled_samples = downsampled_sensor_data.shape[0]\n",
        "\n",
        "        # Determine the effective sampling rate for this sensor to calculate window_samples\n",
        "        current_segmentation_sampling_rate = 0\n",
        "        if sensor_to_segment == 'ECG':\n",
        "            current_segmentation_sampling_rate = ecg_target_sampling_rate\n",
        "        elif sensor_to_segment == 'EDA':\n",
        "            current_segmentation_sampling_rate = eda_target_sampling_rate\n",
        "        elif sensor_to_segment == 'Resp':\n",
        "            current_segmentation_sampling_rate = resp_target_sampling_rate\n",
        "\n",
        "        if current_segmentation_sampling_rate == 0:\n",
        "            print(f\"  Error: Could not determine segmentation sampling rate for {sensor_to_segment}. Skipping segmentation.\")\n",
        "            continue\n",
        "\n",
        "        # Calculate window and step size in samples based on the sensor's desired sampling rate\n",
        "        current_window_samples = int(window_size * current_segmentation_sampling_rate)\n",
        "        current_step_samples = int(current_window_samples * (1 - overlap))\n",
        "\n",
        "        if current_window_samples == 0 or current_step_samples == 0:\n",
        "            print(f\"  Warning: Window or step size for {sensor_to_segment} is zero, skipping segmentation.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        for start_sample_downsampled in range(0, num_downsampled_samples - current_window_samples + 1, current_step_samples):\n",
        "            end_sample_downsampled = start_sample_downsampled + current_window_samples\n",
        "\n",
        "            segment = downsampled_sensor_data[start_sample_downsampled:end_sample_downsampled]\n",
        "\n",
        "            # Map downsampled segment indices back to original label indices\n",
        "            sampling_rate_ratio = original_chest_sampling_rate / current_segmentation_sampling_rate\n",
        "\n",
        "            original_start_sample_for_label = int(start_sample_downsampled * sampling_rate_ratio)\n",
        "            original_end_sample_for_label = int(end_sample_downsampled * sampling_rate_ratio)\n",
        "\n",
        "            # Ensure original_end_sample_for_label does not exceed original_labels length\n",
        "            original_end_sample_for_label = min(original_end_sample_for_label, len(original_labels))\n",
        "            original_start_sample_for_label = min(original_start_sample_for_label, original_end_sample_for_label) # Ensure start is not after end\n",
        "\n",
        "            if original_start_sample_for_label >= original_end_sample_for_label:\n",
        "                continue # Skip if no valid range for labels\n",
        "\n",
        "            segment_labels_original = original_labels[original_start_sample_for_label:original_end_sample_for_label]\n",
        "\n",
        "            # Assign label based on the most frequent among 0-4, ignoring 5, 6, 7\n",
        "            valid_labels = segment_labels_original[(segment_labels_original >= 0) & (segment_labels_original <= 4)]\n",
        "\n",
        "            if len(valid_labels) > 0:\n",
        "                unique_labels, counts = np.unique(valid_labels, return_counts=True)\n",
        "                most_frequent_label = unique_labels[np.argmax(counts)]\n",
        "\n",
        "                all_segmented_data_by_sensor[sensor_to_segment].append(segment)\n",
        "                all_segmented_labels_by_sensor[sensor_to_segment].append(most_frequent_label)\n",
        "            else:\n",
        "                # If no valid labels (0-4) are found, skip this segment\n",
        "                continue\n",
        "\n",
        "print(\"\\n--- All Subjects Processing Complete ---\")\n",
        "\n",
        "# 5. Print the total number of segments created for each sensor type\n",
        "print(\"\\nTotal segments created per sensor type:\")\n",
        "for sensor, segments_list in all_segmented_data_by_sensor.items():\n",
        "    print(f\"  {sensor}: {len(segments_list)} segments\")\n",
        "    if len(segments_list) > 0:\n",
        "        print(f\"    Sample segment shape: {segments_list[0].shape}\")\n",
        "\n",
        "# 6. Print the distribution of multi-class labels across all combined segments\n",
        "print(\"\\nDistribution of multi-class labels across all combined segments:\")\n",
        "all_labels_combined_for_report = []\n",
        "for sensor in relevant_sensors_for_segmentation:\n",
        "    all_labels_combined_for_report.extend(all_segmented_labels_by_sensor[sensor])\n",
        "\n",
        "if len(all_labels_combined_for_report) > 0:\n",
        "    unique_labels, counts = np.unique(all_labels_combined_for_report, return_counts=True)\n",
        "    for label, count in zip(unique_labels, counts):\n",
        "        print(f\"  Label {label}: {count} segments\")\n",
        "else:\n",
        "    print(\"  No segments with valid labels were created.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subject 1/15...\n",
            "Processing subject 2/15...\n",
            "Processing subject 3/15...\n",
            "Processing subject 4/15...\n",
            "Processing subject 5/15...\n",
            "Processing subject 6/15...\n",
            "Processing subject 7/15...\n",
            "Processing subject 8/15...\n",
            "Processing subject 9/15...\n",
            "Processing subject 10/15...\n",
            "Processing subject 11/15...\n",
            "Processing subject 12/15...\n",
            "Processing subject 13/15...\n",
            "Processing subject 14/15...\n",
            "Processing subject 15/15...\n",
            "\n",
            "--- All Subjects Processing Complete ---\n",
            "\n",
            "Total segments created per sensor type:\n",
            "  ECG: 5701 segments\n",
            "    Sample segment shape: (3750, 1)\n",
            "  Resp: 5701 segments\n",
            "    Sample segment shape: (750, 1)\n",
            "  EDA: 5701 segments\n",
            "    Sample segment shape: (120, 1)\n",
            "\n",
            "Distribution of multi-class labels across all combined segments:\n",
            "  Label 0: 8115 segments\n",
            "  Label 1: 3519 segments\n",
            "  Label 2: 2001 segments\n",
            "  Label 3: 1113 segments\n",
            "  Label 4: 2355 segments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "841cf06d",
        "outputId": "c89c67f7-98a5-4966-cd14-3baaa16f79e3"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Convert segmented data to NumPy arrays\n",
        "X_ecg = np.array(all_segmented_data_by_sensor['ECG'])\n",
        "X_resp = np.array(all_segmented_data_by_sensor['Resp'])\n",
        "X_eda = np.array(all_segmented_data_by_sensor['EDA'])\n",
        "\n",
        "# Ensure all arrays have the same number of segments\n",
        "min_segments = min(X_ecg.shape[0], X_resp.shape[0], X_eda.shape[0])\n",
        "X_ecg = X_ecg[:min_segments]\n",
        "X_resp = X_resp[:min_segments]\n",
        "X_eda = X_eda[:min_segments]\n",
        "# Create y labels\n",
        "y_labels = np.array(all_segmented_labels_by_sensor['ECG']) # Assuming labels are consistent across sensors\n",
        "y_labels = y_labels[:min_segments]\n",
        "\n",
        "\n",
        "# ECG Standardization\n",
        "num_segments_ecg, sequence_length_ecg, num_features_ecg = X_ecg.shape\n",
        "scaler_ecg = StandardScaler()\n",
        "X_ecg_scaled = scaler_ecg.fit_transform(X_ecg.reshape(-1, num_features_ecg)).reshape(num_segments_ecg, sequence_length_ecg, num_features_ecg)\n",
        "\n",
        "# Respiration Standardization\n",
        "num_segments_resp, sequence_length_resp, num_features_resp = X_resp.shape\n",
        "scaler_resp = StandardScaler()\n",
        "X_resp_scaled = scaler_resp.fit_transform(X_resp.reshape(-1, num_features_resp)).reshape(num_segments_resp, sequence_length_resp, num_features_resp)\n",
        "\n",
        "# EDA Standardization\n",
        "num_segments_eda, sequence_length_eda, num_features_eda = X_eda.shape\n",
        "scaler_eda = StandardScaler()\n",
        "X_eda_scaled = scaler_eda.fit_transform(X_eda.reshape(-1, num_features_eda)).reshape(num_segments_eda, sequence_length_eda, num_features_eda)\n",
        "\n",
        "\n",
        "# Split into training and temporary sets (40% train, 60% temp to reduce training data)\n",
        "X_train_ecg, X_temp_ecg, X_train_resp, X_temp_resp, X_train_eda, X_temp_eda, y_train, y_temp = train_test_split(\n",
        "    X_ecg_scaled, X_resp_scaled, X_eda_scaled, y_labels,\n",
        "    test_size=0.6, random_state=42, stratify=y_labels\n",
        ")\n",
        "\n",
        "# Split the temporary set into validation and test sets (50% val, 50% test of temp set)\n",
        "X_val_ecg, X_test_ecg, X_val_resp, X_test_resp, X_val_eda, X_test_eda, y_val, y_test = train_test_split(\n",
        "    X_temp_ecg, X_temp_resp, X_temp_eda, y_temp,\n",
        "    test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Print/QA sizes of the datasets\n",
        "print(f\"Size of X_train_ecg: {X_train_ecg.shape}\")\n",
        "print(f\"Size of X_train_resp: {X_train_resp.shape}\")\n",
        "print(f\"Size of X_train_eda: {X_train_eda.shape}\")\n",
        "print(f\"Size of y_train: {y_train.shape}\")\n",
        "print(f\"Size of X_val_ecg: {X_val_ecg.shape}\")\n",
        "print(f\"Size of X_val_resp: {X_val_resp.shape}\")\n",
        "print(f\"Size of X_val_eda: {X_val_eda.shape}\")\n",
        "print(f\"Size of y_val: {y_val.shape}\")\n",
        "print(f\"Size of X_test_ecg: {X_test_ecg.shape}\")\n",
        "print(f\"Size of X_test_resp: {X_test_resp.shape}\")\n",
        "print(f\"Size of X_test_eda: {X_test_eda.shape}\")\n",
        "print(f\"Size of y_test: {y_test.shape}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X_train_ecg: (2280, 3750, 1)\n",
            "Size of X_train_resp: (2280, 750, 1)\n",
            "Size of X_train_eda: (2280, 120, 1)\n",
            "Size of y_train: (2280,)\n",
            "Size of X_val_ecg: (1710, 3750, 1)\n",
            "Size of X_val_resp: (1710, 750, 1)\n",
            "Size of X_val_eda: (1710, 120, 1)\n",
            "Size of y_val: (1710,)\n",
            "Size of X_test_ecg: (1711, 3750, 1)\n",
            "Size of X_test_resp: (1711, 750, 1)\n",
            "Size of X_test_eda: (1711, 120, 1)\n",
            "Size of y_test: (1711,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2278d705",
        "outputId": "447408be-6726-4ad9-f1f5-5fdac5ccb77e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Constants for physics-informed losses\n",
        "EDA_SAMPLING_RATE = 4  # Hz, as defined in preprocessing for downsampled EDA\n",
        "ALPHA_EDA = 0.01\n",
        "BETA_EDA = 0.1\n",
        "RESP_NORMAL_MIN = 6\n",
        "RESP_NORMAL_MAX = 30\n",
        "LAMBDA_EDA_ODE = 1.0\n",
        "LAMBDA_RESP_RANGE = 1.0\n",
        "LAMBDA_HR_SMOOTHNESS = 1.0\n",
        "\n",
        "# 1. Define L_EDA_ODE loss function\n",
        "def L_EDA_ODE(s_true, u_pred, sampling_rate=EDA_SAMPLING_RATE, alpha=ALPHA_EDA, beta=BETA_EDA):\n",
        "    \"\"\"Calculates the Mean Squared Error (MSE) between the derivative of the EDA signal (s_true)\n",
        "    and (-alpha * s(t) + beta * u(t)).\n",
        "\n",
        "    Args:\n",
        "        s_true (tf.Tensor): The original EDA signal (eda_input). Shape (batch_size, sequence_length, 1).\n",
        "        u_pred (tf.Tensor): Predicted EDA latent driver u(t). Shape (batch_size, 1).\n",
        "        sampling_rate (int): Sampling rate of the EDA signal.\n",
        "        alpha (float): Parameter alpha, representing passive decay.\n",
        "        beta (float): Parameter beta, representing sudomotor nerve activity gain.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: L_EDA_ODE loss value.\n",
        "    \"\"\"\n",
        "    s_true_squeezed = tf.squeeze(s_true, axis=-1)  # (batch_size, sequence_length)\n",
        "    s_true_float = tf.cast(s_true_squeezed, dtype=tf.float32)\n",
        "\n",
        "    # Approximate derivative of s_true using finite differences\n",
        "    s_dot_approx = (s_true_float[:, 1:] - s_true_float[:, :-1]) * sampling_rate\n",
        "    s_true_clipped = s_true_float[:, :-1]\n",
        "\n",
        "    # Reshape u_pred to (batch_size, 1) and tile it to match s_dot_approx's sequence length\n",
        "    u_pred_squeezed = tf.squeeze(u_pred, axis=-1)  # (batch_size,)\n",
        "    u_pred_expanded = tf.expand_dims(u_pred_squeezed, axis=-1)  # (batch_size, 1)\n",
        "    u_pred_expanded = tf.tile(u_pred_expanded, [1, tf.shape(s_true_clipped)[1]])  # (batch_size, sequence_length-1)\n",
        "\n",
        "    # Target derivative based on the ODE\n",
        "    target_s_dot = -alpha * s_true_clipped + beta * u_pred_expanded\n",
        "\n",
        "    # Calculate MSE between approximated s_dot and target_s_dot\n",
        "    loss = tf.reduce_mean(tf.square(s_dot_approx - target_s_dot))\n",
        "    return loss\n",
        "\n",
        "\n",
        "# 2. Define L_Resp_Range loss function\n",
        "def L_Resp_Range(resp_rate_pred, normal_min=RESP_NORMAL_MIN, normal_max=RESP_NORMAL_MAX):\n",
        "    \"\"\"Penalizes predicted respiration rate values falling outside the normal physiological range.\n",
        "\n",
        "    Args:\n",
        "        resp_rate_pred (tf.Tensor): Predicted respiration rate (breaths/min). Shape (batch_size, 1).\n",
        "        normal_min (int): Minimum normal respiration rate.\n",
        "        normal_max (int): Maximum normal respiration rate.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: L_Resp_Range loss value.\n",
        "    \"\"\"\n",
        "    resp_rate_pred_squeezed = tf.squeeze(resp_rate_pred, axis=-1)  # (batch_size,)\n",
        "\n",
        "    # Penalty for values below the normal minimum\n",
        "    below_min_penalty = tf.square(tf.maximum(0.0, normal_min - resp_rate_pred_squeezed))\n",
        "    # Penalty for values above the normal maximum\n",
        "    above_max_penalty = tf.square(tf.maximum(0.0, resp_rate_pred_squeezed - normal_max))\n",
        "\n",
        "    loss = tf.reduce_mean(below_min_penalty + above_max_penalty)\n",
        "    return loss\n",
        "\n",
        "# 3. Define L_HR_Smoothness loss function\n",
        "def L_HR_Smoothness(hr_proxy_features):\n",
        "    \"\"\"Penalizes the magnitude of heart rate proxy features to encourage \"smoothness\" (less spiky).\n",
        "\n",
        "    Args:\n",
        "        hr_proxy_features (tf.Tensor): Features from the ECG branch output (e.g., ecg_bilstm output)\n",
        "                                       Shape (batch_size, feature_dim).\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: L_HR_Smoothness loss value.\n",
        "    \"\"\"\n",
        "    # Penalize the L2 norm of the feature vector, encouraging smaller magnitudes.\n",
        "    # This acts as a form of regularization on the latent representation.\n",
        "    loss = tf.reduce_mean(tf.square(hr_proxy_features))\n",
        "    return loss\n",
        "\n",
        "print(\"Custom physics-informed loss functions updated and defined.\")\n",
        "\n",
        "# Custom combined loss function for model.compile\n",
        "def combined_pinn_loss_for_compile(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Combined loss function for PINN model.\n",
        "\n",
        "    Args:\n",
        "        y_true (list): List of true labels for all model outputs.\n",
        "        y_pred (list): List of all model outputs:\n",
        "                             [classification_output, eda_latent_output, resp_cycle_output, ecg_bilstm_output, eda_input_original_passed_through]\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Total combined loss.\n",
        "    \"\"\"\n",
        "    # Unpack y_true (list of targets from model.fit). y_true[4] was mismapped, so we avoid using it for s_true.\n",
        "    y_true_classification = y_true[0]\n",
        "\n",
        "    # Unpack y_pred (list of model outputs)\n",
        "    classification_output = y_pred[0]\n",
        "    eda_latent_output = y_pred[1]\n",
        "    resp_cycle_output = y_pred[2]\n",
        "    ecg_bilstm_output = y_pred[3]\n",
        "    eda_input_original_passed_through = y_pred[4] # This is the original eda_input passed as an output\n",
        "\n",
        "    # Reshape y_true_classification to (batch_size, 1) if it's currently (batch_size,)\n",
        "    if y_true_classification.shape.ndims == 1:\n",
        "        y_true_classification = tf.expand_dims(y_true_classification, axis=-1)\n",
        "\n",
        "    # 1. Classification Loss (SparseCategoricalCrossentropy)\n",
        "    classification_loss_fn = SparseCategoricalCrossentropy(from_logits=False)\n",
        "    l_classification = classification_loss_fn(y_true_classification, classification_output)\n",
        "\n",
        "    # 2. L_EDA_ODE Loss\n",
        "    # s_true corresponds to the eda_input that was passed through as an output (y_pred[4])\n",
        "    # u_pred corresponds to eda_latent_output (y_pred[1])\n",
        "    l_eda_ode = L_EDA_ODE(s_true=eda_input_original_passed_through, u_pred=eda_latent_output)\n",
        "\n",
        "    # 3. L_Resp_Range Loss\n",
        "    # resp_rate_pred corresponds to resp_cycle_output (y_pred[2])\n",
        "    l_resp_range = L_Resp_Range(resp_rate_pred=resp_cycle_output)\n",
        "\n",
        "    # 4. L_HR_Smoothness Loss\n",
        "    # hr_proxy_features corresponds to ecg_bilstm_output (y_pred[3])\n",
        "    l_hr_smoothness = L_HR_Smoothness(hr_proxy_features=ecg_bilstm_output)\n",
        "\n",
        "    # Total combined loss\n",
        "    total_loss = l_classification + \\\n",
        "                 LAMBDA_EDA_ODE * l_eda_ode + \\\n",
        "                 LAMBDA_RESP_RANGE * l_resp_range + \\\n",
        "                 LAMBDA_HR_SMOOTHNESS * l_hr_smoothness\n",
        "    return total_loss\n",
        "\n",
        "print(\"Custom combined loss function for model.compile defined.\")\n",
        "\n",
        "# Compile the model\n",
        "# Keras will pass y_true as a list of targets (y_train_targets) and y_pred as a list of model outputs\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=combined_pinn_loss_for_compile,\n",
        "    metrics={'classification_output': 'accuracy'} # Monitor classification accuracy for the main task\n",
        ")\n",
        "\n",
        "print(\"PINN model compiled successfully with custom combined loss and classification accuracy metric.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom physics-informed loss functions updated and defined.\n",
            "Custom combined loss function for model.compile defined.\n",
            "PINN model compiled successfully with custom combined loss and classification accuracy metric.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train PINN model"
      ],
      "metadata": {
        "id": "2lza5dxaH6LM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb4c9971",
        "outputId": "a4e891a5-8770-4797-cdae-45f0b30aafd5"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# For training data\n",
        "num_train_samples = tf.shape(y_train)[0]\n",
        "\n",
        "y_train_targets = {\n",
        "    'classification_output': y_train,                       # Target for 'classification_output'\n",
        "    # Dummy targets for physics-informed outputs are still required by Keras even if their\n",
        "    # primary loss comes from model.add_loss. They serve as placeholders.\n",
        "    'eda_latent_driver_output': tf.zeros((num_train_samples, 1), dtype=tf.float32),        # Dummy target\n",
        "    'resp_cycle_detection_output': tf.zeros((num_train_samples, 1), dtype=tf.float32),        # Dummy target\n",
        "    'ecg_bilstm_output': tf.zeros((num_train_samples, 64), dtype=tf.float32)        # Dummy target for L_HR_Smoothness (if not explicit output)\n",
        "}\n",
        "\n",
        "# For validation data\n",
        "num_val_samples = tf.shape(y_val)[0]\n",
        "\n",
        "y_val_targets = {\n",
        "    'classification_output': y_val,                         # Target for 'classification_output'\n",
        "    # Dummy targets for physics-informed outputs\n",
        "    'eda_latent_driver_output': tf.zeros((num_val_samples, 1), dtype=tf.float32),          # Dummy target\n",
        "    'resp_cycle_detection_output': tf.zeros((num_val_samples, 1), dtype=tf.float32),          # Dummy target\n",
        "    'ecg_bilstm_output': tf.zeros((num_val_samples, 64), dtype=tf.float32)          # Dummy target\n",
        "}\n",
        "\n",
        "# 1. Train the model\n",
        "history = model.fit(\n",
        "    [X_train_ecg, X_train_resp, X_train_eda], # Inputs for the three modalities\n",
        "    y_train_targets,                         # Dictionary of targets for all model outputs\n",
        "    epochs=80,\n",
        "    batch_size=32,\n",
        "    validation_data=(\n",
        "        [X_val_ecg, X_val_resp, X_val_eda],\n",
        "        y_val_targets                        # Dictionary of targets for validation data\n",
        "    ),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "print(\"PINN model training initiated.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - classification_output_accuracy: 0.4553 - classification_output_loss: 1.4437 - ecg_bilstm_output_loss: 0.0045 - eda_latent_driver_output_loss: 0.0019 - loss: 1.4512 - resp_cycle_detection_output_loss: 0.0011 - val_classification_output_accuracy: 0.4743 - val_classification_output_loss: 1.3572 - val_ecg_bilstm_output_loss: 0.0028 - val_eda_latent_driver_output_loss: 8.1738e-05 - val_loss: 1.3662 - val_resp_cycle_detection_output_loss: 9.1339e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 3s/step - classification_output_accuracy: 0.4784 - classification_output_loss: 1.3044 - ecg_bilstm_output_loss: 0.0023 - eda_latent_driver_output_loss: 5.9103e-05 - loss: 1.3071 - resp_cycle_detection_output_loss: 1.1302e-04 - val_classification_output_accuracy: 0.4795 - val_classification_output_loss: 1.2898 - val_ecg_bilstm_output_loss: 0.0024 - val_eda_latent_driver_output_loss: 4.7430e-05 - val_loss: 1.2963 - val_resp_cycle_detection_output_loss: 1.4053e-04\n",
            "Epoch 3/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3s/step - classification_output_accuracy: 0.4807 - classification_output_loss: 1.2903 - ecg_bilstm_output_loss: 0.0028 - eda_latent_driver_output_loss: 9.6452e-05 - loss: 1.2934 - resp_cycle_detection_output_loss: 1.7809e-04 - val_classification_output_accuracy: 0.4854 - val_classification_output_loss: 1.2418 - val_ecg_bilstm_output_loss: 0.0066 - val_eda_latent_driver_output_loss: 1.0382e-04 - val_loss: 1.2532 - val_resp_cycle_detection_output_loss: 2.6145e-04\n",
            "Epoch 4/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 3s/step - classification_output_accuracy: 0.4929 - classification_output_loss: 1.2513 - ecg_bilstm_output_loss: 0.0053 - eda_latent_driver_output_loss: 1.0666e-04 - loss: 1.2571 - resp_cycle_detection_output_loss: 3.8900e-04 - val_classification_output_accuracy: 0.4930 - val_classification_output_loss: 1.2483 - val_ecg_bilstm_output_loss: 0.0031 - val_eda_latent_driver_output_loss: 9.4910e-05 - val_loss: 1.2554 - val_resp_cycle_detection_output_loss: 8.0991e-04\n",
            "Epoch 5/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - classification_output_accuracy: 0.4771 - classification_output_loss: 1.2406 - ecg_bilstm_output_loss: 0.0033 - eda_latent_driver_output_loss: 1.1456e-04 - loss: 1.2446 - resp_cycle_detection_output_loss: 5.2641e-04 - val_classification_output_accuracy: 0.4895 - val_classification_output_loss: 1.2121 - val_ecg_bilstm_output_loss: 0.0134 - val_eda_latent_driver_output_loss: 1.2100e-04 - val_loss: 1.2289 - val_resp_cycle_detection_output_loss: 9.5143e-04\n",
            "Epoch 6/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3s/step - classification_output_accuracy: 0.4921 - classification_output_loss: 1.2204 - ecg_bilstm_output_loss: 0.0060 - eda_latent_driver_output_loss: 1.3279e-04 - loss: 1.2277 - resp_cycle_detection_output_loss: 0.0011 - val_classification_output_accuracy: 0.4895 - val_classification_output_loss: 1.2027 - val_ecg_bilstm_output_loss: 0.0050 - val_eda_latent_driver_output_loss: 6.6462e-05 - val_loss: 1.2128 - val_resp_cycle_detection_output_loss: 0.0011\n",
            "Epoch 7/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - classification_output_accuracy: 0.5030 - classification_output_loss: 1.1895 - ecg_bilstm_output_loss: 0.0068 - eda_latent_driver_output_loss: 9.9672e-05 - loss: 1.1975 - resp_cycle_detection_output_loss: 0.0011 - val_classification_output_accuracy: 0.4766 - val_classification_output_loss: 1.2336 - val_ecg_bilstm_output_loss: 0.0200 - val_eda_latent_driver_output_loss: 9.2815e-05 - val_loss: 1.2583 - val_resp_cycle_detection_output_loss: 0.0011\n",
            "Epoch 8/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - classification_output_accuracy: 0.5150 - classification_output_loss: 1.1671 - ecg_bilstm_output_loss: 0.0113 - eda_latent_driver_output_loss: 9.7544e-05 - loss: 1.1792 - resp_cycle_detection_output_loss: 8.7787e-04 - val_classification_output_accuracy: 0.5520 - val_classification_output_loss: 1.0872 - val_ecg_bilstm_output_loss: 0.0118 - val_eda_latent_driver_output_loss: 7.3510e-05 - val_loss: 1.1022 - val_resp_cycle_detection_output_loss: 0.0014\n",
            "Epoch 9/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - classification_output_accuracy: 0.5143 - classification_output_loss: 1.1553 - ecg_bilstm_output_loss: 0.0160 - eda_latent_driver_output_loss: 1.0025e-04 - loss: 1.1725 - resp_cycle_detection_output_loss: 0.0010 - val_classification_output_accuracy: 0.5345 - val_classification_output_loss: 1.1862 - val_ecg_bilstm_output_loss: 0.0067 - val_eda_latent_driver_output_loss: 1.4857e-04 - val_loss: 1.1997 - val_resp_cycle_detection_output_loss: 0.0010\n",
            "Epoch 10/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - classification_output_accuracy: 0.5199 - classification_output_loss: 1.1801 - ecg_bilstm_output_loss: 0.0085 - eda_latent_driver_output_loss: 1.0606e-04 - loss: 1.1902 - resp_cycle_detection_output_loss: 0.0014 - val_classification_output_accuracy: 0.5170 - val_classification_output_loss: 1.1532 - val_ecg_bilstm_output_loss: 0.0087 - val_eda_latent_driver_output_loss: 1.4357e-04 - val_loss: 1.1668 - val_resp_cycle_detection_output_loss: 0.0018\n",
            "Epoch 11/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - classification_output_accuracy: 0.5472 - classification_output_loss: 1.1002 - ecg_bilstm_output_loss: 0.0108 - eda_latent_driver_output_loss: 1.5537e-04 - loss: 1.1128 - resp_cycle_detection_output_loss: 0.0016 - val_classification_output_accuracy: 0.5503 - val_classification_output_loss: 1.0901 - val_ecg_bilstm_output_loss: 0.0109 - val_eda_latent_driver_output_loss: 1.2630e-04 - val_loss: 1.1070 - val_resp_cycle_detection_output_loss: 0.0015\n",
            "Epoch 12/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - classification_output_accuracy: 0.5670 - classification_output_loss: 1.0514 - ecg_bilstm_output_loss: 0.0120 - eda_latent_driver_output_loss: 1.2369e-04 - loss: 1.0650 - resp_cycle_detection_output_loss: 0.0015 - val_classification_output_accuracy: 0.5304 - val_classification_output_loss: 1.1867 - val_ecg_bilstm_output_loss: 0.0433 - val_eda_latent_driver_output_loss: 3.4127e-04 - val_loss: 1.2349 - val_resp_cycle_detection_output_loss: 0.0015\n",
            "Epoch 13/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - classification_output_accuracy: 0.5694 - classification_output_loss: 1.0576 - ecg_bilstm_output_loss: 0.0276 - eda_latent_driver_output_loss: 3.2761e-04 - loss: 1.0867 - resp_cycle_detection_output_loss: 0.0013 - val_classification_output_accuracy: 0.5906 - val_classification_output_loss: 1.0156 - val_ecg_bilstm_output_loss: 0.0180 - val_eda_latent_driver_output_loss: 1.4642e-04 - val_loss: 1.0380 - val_resp_cycle_detection_output_loss: 0.0011\n",
            "Epoch 14/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - classification_output_accuracy: 0.5975 - classification_output_loss: 0.9844 - ecg_bilstm_output_loss: 0.0157 - eda_latent_driver_output_loss: 2.0776e-04 - loss: 1.0013 - resp_cycle_detection_output_loss: 0.0010 - val_classification_output_accuracy: 0.5363 - val_classification_output_loss: 1.1520 - val_ecg_bilstm_output_loss: 0.0154 - val_eda_latent_driver_output_loss: 1.3258e-04 - val_loss: 1.1747 - val_resp_cycle_detection_output_loss: 0.0013\n",
            "Epoch 15/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - classification_output_accuracy: 0.5519 - classification_output_loss: 1.0771 - ecg_bilstm_output_loss: 0.0154 - eda_latent_driver_output_loss: 1.1921e-04 - loss: 1.0939 - resp_cycle_detection_output_loss: 0.0014 - val_classification_output_accuracy: 0.5573 - val_classification_output_loss: 1.0550 - val_ecg_bilstm_output_loss: 0.0194 - val_eda_latent_driver_output_loss: 3.7758e-05 - val_loss: 1.0807 - val_resp_cycle_detection_output_loss: 9.7047e-04\n",
            "Epoch 16/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - classification_output_accuracy: 0.6129 - classification_output_loss: 0.9589 - ecg_bilstm_output_loss: 0.0191 - eda_latent_driver_output_loss: 9.8831e-05 - loss: 0.9791 - resp_cycle_detection_output_loss: 9.7690e-04 - val_classification_output_accuracy: 0.5602 - val_classification_output_loss: 1.0518 - val_ecg_bilstm_output_loss: 0.0143 - val_eda_latent_driver_output_loss: 8.0720e-05 - val_loss: 1.0697 - val_resp_cycle_detection_output_loss: 0.0010\n",
            "Epoch 17/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - classification_output_accuracy: 0.6124 - classification_output_loss: 0.9370 - ecg_bilstm_output_loss: 0.0137 - eda_latent_driver_output_loss: 1.5344e-04 - loss: 0.9518 - resp_cycle_detection_output_loss: 9.3493e-04 - val_classification_output_accuracy: 0.5930 - val_classification_output_loss: 0.9772 - val_ecg_bilstm_output_loss: 0.0149 - val_eda_latent_driver_output_loss: 1.3463e-04 - val_loss: 0.9974 - val_resp_cycle_detection_output_loss: 9.3015e-04\n",
            "Epoch 18/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - classification_output_accuracy: 0.6380 - classification_output_loss: 0.9125 - ecg_bilstm_output_loss: 0.0136 - eda_latent_driver_output_loss: 1.5247e-04 - loss: 0.9271 - resp_cycle_detection_output_loss: 8.3949e-04 - val_classification_output_accuracy: 0.5942 - val_classification_output_loss: 0.9974 - val_ecg_bilstm_output_loss: 0.0159 - val_eda_latent_driver_output_loss: 1.0725e-04 - val_loss: 1.0188 - val_resp_cycle_detection_output_loss: 8.6314e-04\n",
            "Epoch 19/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - classification_output_accuracy: 0.6379 - classification_output_loss: 0.8752 - ecg_bilstm_output_loss: 0.0154 - eda_latent_driver_output_loss: 1.1749e-04 - loss: 0.8914 - resp_cycle_detection_output_loss: 8.2956e-04 - val_classification_output_accuracy: 0.5643 - val_classification_output_loss: 1.0422 - val_ecg_bilstm_output_loss: 0.0193 - val_eda_latent_driver_output_loss: 1.7377e-04 - val_loss: 1.0645 - val_resp_cycle_detection_output_loss: 0.0012\n",
            "Epoch 20/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - classification_output_accuracy: 0.5947 - classification_output_loss: 1.0032 - ecg_bilstm_output_loss: 0.0188 - eda_latent_driver_output_loss: 1.3513e-04 - loss: 1.0235 - resp_cycle_detection_output_loss: 0.0013 - val_classification_output_accuracy: 0.6187 - val_classification_output_loss: 0.9430 - val_ecg_bilstm_output_loss: 0.0201 - val_eda_latent_driver_output_loss: 6.3779e-05 - val_loss: 0.9678 - val_resp_cycle_detection_output_loss: 0.0010\n",
            "Epoch 21/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - classification_output_accuracy: 0.6715 - classification_output_loss: 0.8152 - ecg_bilstm_output_loss: 0.0198 - eda_latent_driver_output_loss: 9.9977e-05 - loss: 0.8361 - resp_cycle_detection_output_loss: 9.5945e-04 - val_classification_output_accuracy: 0.6099 - val_classification_output_loss: 0.9386 - val_ecg_bilstm_output_loss: 0.0197 - val_eda_latent_driver_output_loss: 6.3940e-05 - val_loss: 0.9612 - val_resp_cycle_detection_output_loss: 6.1601e-04\n",
            "Epoch 22/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - classification_output_accuracy: 0.6523 - classification_output_loss: 0.8382 - ecg_bilstm_output_loss: 0.0205 - eda_latent_driver_output_loss: 9.2343e-05 - loss: 0.8595 - resp_cycle_detection_output_loss: 7.2425e-04 - val_classification_output_accuracy: 0.6421 - val_classification_output_loss: 0.8864 - val_ecg_bilstm_output_loss: 0.0192 - val_eda_latent_driver_output_loss: 1.2209e-04 - val_loss: 0.9093 - val_resp_cycle_detection_output_loss: 6.1899e-04\n",
            "Epoch 23/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - classification_output_accuracy: 0.6795 - classification_output_loss: 0.7969 - ecg_bilstm_output_loss: 0.0202 - eda_latent_driver_output_loss: 1.1421e-04 - loss: 0.8179 - resp_cycle_detection_output_loss: 6.4713e-04 - val_classification_output_accuracy: 0.6094 - val_classification_output_loss: 0.9377 - val_ecg_bilstm_output_loss: 0.0248 - val_eda_latent_driver_output_loss: 1.1931e-04 - val_loss: 0.9659 - val_resp_cycle_detection_output_loss: 6.8927e-04\n",
            "Epoch 24/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3s/step - classification_output_accuracy: 0.6736 - classification_output_loss: 0.7880 - ecg_bilstm_output_loss: 0.0219 - eda_latent_driver_output_loss: 1.3524e-04 - loss: 0.8106 - resp_cycle_detection_output_loss: 6.6826e-04 - val_classification_output_accuracy: 0.6251 - val_classification_output_loss: 0.8977 - val_ecg_bilstm_output_loss: 0.0216 - val_eda_latent_driver_output_loss: 1.3540e-04 - val_loss: 0.9233 - val_resp_cycle_detection_output_loss: 6.9806e-04\n",
            "Epoch 25/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - classification_output_accuracy: 0.6679 - classification_output_loss: 0.8124 - ecg_bilstm_output_loss: 0.0211 - eda_latent_driver_output_loss: 1.7680e-04 - loss: 0.8342 - resp_cycle_detection_output_loss: 6.8074e-04 - val_classification_output_accuracy: 0.6152 - val_classification_output_loss: 0.9129 - val_ecg_bilstm_output_loss: 0.0178 - val_eda_latent_driver_output_loss: 2.1795e-04 - val_loss: 0.9327 - val_resp_cycle_detection_output_loss: 6.9411e-04\n",
            "Epoch 26/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - classification_output_accuracy: 0.6863 - classification_output_loss: 0.7769 - ecg_bilstm_output_loss: 0.0189 - eda_latent_driver_output_loss: 1.7833e-04 - loss: 0.7967 - resp_cycle_detection_output_loss: 6.6509e-04 - val_classification_output_accuracy: 0.6140 - val_classification_output_loss: 0.9627 - val_ecg_bilstm_output_loss: 0.0204 - val_eda_latent_driver_output_loss: 2.1686e-04 - val_loss: 0.9853 - val_resp_cycle_detection_output_loss: 5.3431e-04\n",
            "Epoch 27/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - classification_output_accuracy: 0.6868 - classification_output_loss: 0.7668 - ecg_bilstm_output_loss: 0.0200 - eda_latent_driver_output_loss: 2.5377e-04 - loss: 0.7873 - resp_cycle_detection_output_loss: 4.8870e-04 - val_classification_output_accuracy: 0.6345 - val_classification_output_loss: 0.9008 - val_ecg_bilstm_output_loss: 0.0231 - val_eda_latent_driver_output_loss: 1.8659e-04 - val_loss: 0.9275 - val_resp_cycle_detection_output_loss: 4.8397e-04\n",
            "Epoch 28/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - classification_output_accuracy: 0.6889 - classification_output_loss: 0.7680 - ecg_bilstm_output_loss: 0.0253 - eda_latent_driver_output_loss: 2.0610e-04 - loss: 0.7941 - resp_cycle_detection_output_loss: 5.0143e-04 - val_classification_output_accuracy: 0.6485 - val_classification_output_loss: 0.8573 - val_ecg_bilstm_output_loss: 0.0250 - val_eda_latent_driver_output_loss: 1.1397e-04 - val_loss: 0.8843 - val_resp_cycle_detection_output_loss: 5.4097e-04\n",
            "Epoch 29/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3s/step - classification_output_accuracy: 0.7022 - classification_output_loss: 0.7236 - ecg_bilstm_output_loss: 0.0247 - eda_latent_driver_output_loss: 1.1060e-04 - loss: 0.7491 - resp_cycle_detection_output_loss: 5.9165e-04 - val_classification_output_accuracy: 0.6251 - val_classification_output_loss: 0.8921 - val_ecg_bilstm_output_loss: 0.0237 - val_eda_latent_driver_output_loss: 1.1491e-04 - val_loss: 0.9180 - val_resp_cycle_detection_output_loss: 6.5047e-04\n",
            "Epoch 30/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - classification_output_accuracy: 0.7162 - classification_output_loss: 0.6957 - ecg_bilstm_output_loss: 0.0216 - eda_latent_driver_output_loss: 1.1312e-04 - loss: 0.7181 - resp_cycle_detection_output_loss: 6.3324e-04 - val_classification_output_accuracy: 0.6158 - val_classification_output_loss: 0.9212 - val_ecg_bilstm_output_loss: 0.0202 - val_eda_latent_driver_output_loss: 7.7023e-05 - val_loss: 0.9450 - val_resp_cycle_detection_output_loss: 4.7275e-04\n",
            "Epoch 31/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - classification_output_accuracy: 0.7117 - classification_output_loss: 0.6989 - ecg_bilstm_output_loss: 0.0209 - eda_latent_driver_output_loss: 8.5597e-05 - loss: 0.7204 - resp_cycle_detection_output_loss: 5.2157e-04 - val_classification_output_accuracy: 0.6485 - val_classification_output_loss: 0.8656 - val_ecg_bilstm_output_loss: 0.0219 - val_eda_latent_driver_output_loss: 6.7152e-05 - val_loss: 0.8915 - val_resp_cycle_detection_output_loss: 5.3516e-04\n",
            "Epoch 32/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - classification_output_accuracy: 0.7205 - classification_output_loss: 0.7153 - ecg_bilstm_output_loss: 0.0233 - eda_latent_driver_output_loss: 7.2788e-05 - loss: 0.7392 - resp_cycle_detection_output_loss: 4.9338e-04 - val_classification_output_accuracy: 0.6404 - val_classification_output_loss: 0.8721 - val_ecg_bilstm_output_loss: 0.0243 - val_eda_latent_driver_output_loss: 7.7005e-05 - val_loss: 0.8992 - val_resp_cycle_detection_output_loss: 5.6405e-04\n",
            "Epoch 33/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3s/step - classification_output_accuracy: 0.7210 - classification_output_loss: 0.6775 - ecg_bilstm_output_loss: 0.0259 - eda_latent_driver_output_loss: 6.5080e-05 - loss: 0.7040 - resp_cycle_detection_output_loss: 5.3621e-04 - val_classification_output_accuracy: 0.6345 - val_classification_output_loss: 0.9345 - val_ecg_bilstm_output_loss: 0.0245 - val_eda_latent_driver_output_loss: 7.9535e-05 - val_loss: 0.9645 - val_resp_cycle_detection_output_loss: 5.1591e-04\n",
            "Epoch 34/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - classification_output_accuracy: 0.7389 - classification_output_loss: 0.6561 - ecg_bilstm_output_loss: 0.0224 - eda_latent_driver_output_loss: 8.0240e-05 - loss: 0.6792 - resp_cycle_detection_output_loss: 4.4583e-04 - val_classification_output_accuracy: 0.6591 - val_classification_output_loss: 0.8669 - val_ecg_bilstm_output_loss: 0.0244 - val_eda_latent_driver_output_loss: 5.9197e-05 - val_loss: 0.8919 - val_resp_cycle_detection_output_loss: 4.9176e-04\n",
            "Epoch 35/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - classification_output_accuracy: 0.7272 - classification_output_loss: 0.6489 - ecg_bilstm_output_loss: 0.0234 - eda_latent_driver_output_loss: 7.0825e-05 - loss: 0.6729 - resp_cycle_detection_output_loss: 4.3355e-04 - val_classification_output_accuracy: 0.6386 - val_classification_output_loss: 0.8964 - val_ecg_bilstm_output_loss: 0.0233 - val_eda_latent_driver_output_loss: 7.5113e-05 - val_loss: 0.9225 - val_resp_cycle_detection_output_loss: 4.5002e-04\n",
            "Epoch 36/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - classification_output_accuracy: 0.7373 - classification_output_loss: 0.6285 - ecg_bilstm_output_loss: 0.0232 - eda_latent_driver_output_loss: 8.4071e-05 - loss: 0.6522 - resp_cycle_detection_output_loss: 4.4596e-04 - val_classification_output_accuracy: 0.6427 - val_classification_output_loss: 0.8749 - val_ecg_bilstm_output_loss: 0.0254 - val_eda_latent_driver_output_loss: 5.4947e-05 - val_loss: 0.9036 - val_resp_cycle_detection_output_loss: 4.1151e-04\n",
            "Epoch 37/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3s/step - classification_output_accuracy: 0.7517 - classification_output_loss: 0.6113 - ecg_bilstm_output_loss: 0.0239 - eda_latent_driver_output_loss: 6.6648e-05 - loss: 0.6355 - resp_cycle_detection_output_loss: 3.8025e-04 - val_classification_output_accuracy: 0.6485 - val_classification_output_loss: 0.9247 - val_ecg_bilstm_output_loss: 0.0239 - val_eda_latent_driver_output_loss: 7.6034e-05 - val_loss: 0.9528 - val_resp_cycle_detection_output_loss: 6.2406e-04\n",
            "Epoch 38/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - classification_output_accuracy: 0.7553 - classification_output_loss: 0.6199 - ecg_bilstm_output_loss: 0.0243 - eda_latent_driver_output_loss: 5.8254e-05 - loss: 0.6449 - resp_cycle_detection_output_loss: 4.9914e-04 - val_classification_output_accuracy: 0.6567 - val_classification_output_loss: 0.8768 - val_ecg_bilstm_output_loss: 0.0264 - val_eda_latent_driver_output_loss: 8.6941e-05 - val_loss: 0.9063 - val_resp_cycle_detection_output_loss: 4.2304e-04\n",
            "Epoch 39/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - classification_output_accuracy: 0.7858 - classification_output_loss: 0.5579 - ecg_bilstm_output_loss: 0.0258 - eda_latent_driver_output_loss: 7.8121e-05 - loss: 0.5840 - resp_cycle_detection_output_loss: 4.3322e-04 - val_classification_output_accuracy: 0.6602 - val_classification_output_loss: 0.8466 - val_ecg_bilstm_output_loss: 0.0291 - val_eda_latent_driver_output_loss: 7.0247e-05 - val_loss: 0.8777 - val_resp_cycle_detection_output_loss: 3.7282e-04\n",
            "Epoch 40/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3s/step - classification_output_accuracy: 0.8072 - classification_output_loss: 0.5135 - ecg_bilstm_output_loss: 0.0271 - eda_latent_driver_output_loss: 6.7403e-05 - loss: 0.5411 - resp_cycle_detection_output_loss: 3.6000e-04 - val_classification_output_accuracy: 0.6608 - val_classification_output_loss: 0.8509 - val_ecg_bilstm_output_loss: 0.0259 - val_eda_latent_driver_output_loss: 1.0580e-04 - val_loss: 0.8780 - val_resp_cycle_detection_output_loss: 3.4948e-04\n",
            "Epoch 41/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - classification_output_accuracy: 0.8246 - classification_output_loss: 0.4764 - ecg_bilstm_output_loss: 0.0269 - eda_latent_driver_output_loss: 9.6087e-05 - loss: 0.5036 - resp_cycle_detection_output_loss: 3.3435e-04 - val_classification_output_accuracy: 0.6503 - val_classification_output_loss: 0.8768 - val_ecg_bilstm_output_loss: 0.0289 - val_eda_latent_driver_output_loss: 9.0634e-05 - val_loss: 0.9077 - val_resp_cycle_detection_output_loss: 3.2236e-04\n",
            "Epoch 42/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - classification_output_accuracy: 0.7953 - classification_output_loss: 0.5018 - ecg_bilstm_output_loss: 0.0285 - eda_latent_driver_output_loss: 8.7360e-05 - loss: 0.5308 - resp_cycle_detection_output_loss: 3.2800e-04 - val_classification_output_accuracy: 0.6637 - val_classification_output_loss: 0.9054 - val_ecg_bilstm_output_loss: 0.0299 - val_eda_latent_driver_output_loss: 9.4797e-05 - val_loss: 0.9377 - val_resp_cycle_detection_output_loss: 3.1280e-04\n",
            "Epoch 43/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - classification_output_accuracy: 0.8103 - classification_output_loss: 0.4935 - ecg_bilstm_output_loss: 0.0258 - eda_latent_driver_output_loss: 9.5064e-05 - loss: 0.5198 - resp_cycle_detection_output_loss: 2.9996e-04 - val_classification_output_accuracy: 0.6591 - val_classification_output_loss: 0.8817 - val_ecg_bilstm_output_loss: 0.0318 - val_eda_latent_driver_output_loss: 1.1915e-04 - val_loss: 0.9162 - val_resp_cycle_detection_output_loss: 3.5907e-04\n",
            "Epoch 44/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - classification_output_accuracy: 0.8327 - classification_output_loss: 0.4493 - ecg_bilstm_output_loss: 0.0294 - eda_latent_driver_output_loss: 8.1201e-05 - loss: 0.4790 - resp_cycle_detection_output_loss: 3.3111e-04 - val_classification_output_accuracy: 0.6696 - val_classification_output_loss: 0.8463 - val_ecg_bilstm_output_loss: 0.0304 - val_eda_latent_driver_output_loss: 5.2501e-05 - val_loss: 0.8788 - val_resp_cycle_detection_output_loss: 3.4261e-04\n",
            "Epoch 45/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - classification_output_accuracy: 0.8417 - classification_output_loss: 0.4172 - ecg_bilstm_output_loss: 0.0289 - eda_latent_driver_output_loss: 6.8482e-05 - loss: 0.4465 - resp_cycle_detection_output_loss: 3.0678e-04 - val_classification_output_accuracy: 0.6719 - val_classification_output_loss: 0.8672 - val_ecg_bilstm_output_loss: 0.0335 - val_eda_latent_driver_output_loss: 8.9223e-05 - val_loss: 0.9012 - val_resp_cycle_detection_output_loss: 2.5538e-04\n",
            "Epoch 46/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - classification_output_accuracy: 0.8320 - classification_output_loss: 0.4215 - ecg_bilstm_output_loss: 0.0299 - eda_latent_driver_output_loss: 9.2677e-05 - loss: 0.4517 - resp_cycle_detection_output_loss: 2.6909e-04 - val_classification_output_accuracy: 0.6497 - val_classification_output_loss: 0.9375 - val_ecg_bilstm_output_loss: 0.0310 - val_eda_latent_driver_output_loss: 1.2948e-04 - val_loss: 0.9678 - val_resp_cycle_detection_output_loss: 2.4269e-04\n",
            "Epoch 47/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - classification_output_accuracy: 0.8375 - classification_output_loss: 0.4185 - ecg_bilstm_output_loss: 0.0314 - eda_latent_driver_output_loss: 1.1088e-04 - loss: 0.4502 - resp_cycle_detection_output_loss: 2.3582e-04 - val_classification_output_accuracy: 0.6585 - val_classification_output_loss: 0.8862 - val_ecg_bilstm_output_loss: 0.0377 - val_eda_latent_driver_output_loss: 1.5022e-04 - val_loss: 0.9256 - val_resp_cycle_detection_output_loss: 2.4507e-04\n",
            "Epoch 48/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - classification_output_accuracy: 0.8392 - classification_output_loss: 0.4209 - ecg_bilstm_output_loss: 0.0339 - eda_latent_driver_output_loss: 1.4958e-04 - loss: 0.4551 - resp_cycle_detection_output_loss: 2.5239e-04 - val_classification_output_accuracy: 0.6585 - val_classification_output_loss: 0.8987 - val_ecg_bilstm_output_loss: 0.0338 - val_eda_latent_driver_output_loss: 1.1146e-04 - val_loss: 0.9318 - val_resp_cycle_detection_output_loss: 1.7620e-04\n",
            "Epoch 49/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - classification_output_accuracy: 0.8556 - classification_output_loss: 0.3950 - ecg_bilstm_output_loss: 0.0317 - eda_latent_driver_output_loss: 1.0661e-04 - loss: 0.4270 - resp_cycle_detection_output_loss: 1.9825e-04 - val_classification_output_accuracy: 0.6608 - val_classification_output_loss: 0.9227 - val_ecg_bilstm_output_loss: 0.0358 - val_eda_latent_driver_output_loss: 1.2448e-04 - val_loss: 0.9606 - val_resp_cycle_detection_output_loss: 1.9061e-04\n",
            "Epoch 50/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - classification_output_accuracy: 0.8811 - classification_output_loss: 0.3392 - ecg_bilstm_output_loss: 0.0349 - eda_latent_driver_output_loss: 9.7314e-05 - loss: 0.3743 - resp_cycle_detection_output_loss: 1.8671e-04 - val_classification_output_accuracy: 0.6637 - val_classification_output_loss: 0.8914 - val_ecg_bilstm_output_loss: 0.0312 - val_eda_latent_driver_output_loss: 1.0238e-04 - val_loss: 0.9241 - val_resp_cycle_detection_output_loss: 1.8197e-04\n",
            "Epoch 51/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - classification_output_accuracy: 0.8606 - classification_output_loss: 0.3857 - ecg_bilstm_output_loss: 0.0298 - eda_latent_driver_output_loss: 1.0328e-04 - loss: 0.4157 - resp_cycle_detection_output_loss: 1.9532e-04 - val_classification_output_accuracy: 0.6450 - val_classification_output_loss: 0.9898 - val_ecg_bilstm_output_loss: 0.0293 - val_eda_latent_driver_output_loss: 1.9723e-04 - val_loss: 1.0182 - val_resp_cycle_detection_output_loss: 1.8065e-04\n",
            "Epoch 52/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - classification_output_accuracy: 0.8636 - classification_output_loss: 0.3597 - ecg_bilstm_output_loss: 0.0300 - eda_latent_driver_output_loss: 1.3167e-04 - loss: 0.3898 - resp_cycle_detection_output_loss: 1.7821e-04 - val_classification_output_accuracy: 0.6491 - val_classification_output_loss: 0.9251 - val_ecg_bilstm_output_loss: 0.0323 - val_eda_latent_driver_output_loss: 3.4902e-04 - val_loss: 0.9588 - val_resp_cycle_detection_output_loss: 1.5965e-04\n",
            "Epoch 53/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - classification_output_accuracy: 0.9042 - classification_output_loss: 0.3069 - ecg_bilstm_output_loss: 0.0314 - eda_latent_driver_output_loss: 1.8129e-04 - loss: 0.3386 - resp_cycle_detection_output_loss: 1.4641e-04 - val_classification_output_accuracy: 0.6690 - val_classification_output_loss: 0.9466 - val_ecg_bilstm_output_loss: 0.0317 - val_eda_latent_driver_output_loss: 9.7550e-05 - val_loss: 0.9815 - val_resp_cycle_detection_output_loss: 1.3966e-04\n",
            "Epoch 54/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - classification_output_accuracy: 0.8988 - classification_output_loss: 0.2973 - ecg_bilstm_output_loss: 0.0326 - eda_latent_driver_output_loss: 1.2314e-04 - loss: 0.3302 - resp_cycle_detection_output_loss: 1.4842e-04 - val_classification_output_accuracy: 0.6626 - val_classification_output_loss: 0.9709 - val_ecg_bilstm_output_loss: 0.0327 - val_eda_latent_driver_output_loss: 8.6953e-05 - val_loss: 1.0016 - val_resp_cycle_detection_output_loss: 1.1594e-04\n",
            "Epoch 55/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3s/step - classification_output_accuracy: 0.9051 - classification_output_loss: 0.2738 - ecg_bilstm_output_loss: 0.0325 - eda_latent_driver_output_loss: 9.4943e-05 - loss: 0.3065 - resp_cycle_detection_output_loss: 1.2573e-04 - val_classification_output_accuracy: 0.6801 - val_classification_output_loss: 0.9268 - val_ecg_bilstm_output_loss: 0.0335 - val_eda_latent_driver_output_loss: 1.1030e-04 - val_loss: 0.9641 - val_resp_cycle_detection_output_loss: 1.0833e-04\n",
            "Epoch 56/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - classification_output_accuracy: 0.9242 - classification_output_loss: 0.2612 - ecg_bilstm_output_loss: 0.0335 - eda_latent_driver_output_loss: 1.1465e-04 - loss: 0.2949 - resp_cycle_detection_output_loss: 8.5704e-05 - val_classification_output_accuracy: 0.6772 - val_classification_output_loss: 0.9264 - val_ecg_bilstm_output_loss: 0.0377 - val_eda_latent_driver_output_loss: 1.3350e-04 - val_loss: 0.9626 - val_resp_cycle_detection_output_loss: 7.9663e-05\n",
            "Epoch 57/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - classification_output_accuracy: 0.9356 - classification_output_loss: 0.2187 - ecg_bilstm_output_loss: 0.0352 - eda_latent_driver_output_loss: 1.1466e-04 - loss: 0.2541 - resp_cycle_detection_output_loss: 6.7871e-05 - val_classification_output_accuracy: 0.6626 - val_classification_output_loss: 0.9546 - val_ecg_bilstm_output_loss: 0.0364 - val_eda_latent_driver_output_loss: 1.0403e-04 - val_loss: 0.9938 - val_resp_cycle_detection_output_loss: 8.0045e-05\n",
            "Epoch 58/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - classification_output_accuracy: 0.9221 - classification_output_loss: 0.2263 - ecg_bilstm_output_loss: 0.0353 - eda_latent_driver_output_loss: 9.4728e-05 - loss: 0.2618 - resp_cycle_detection_output_loss: 6.5494e-05 - val_classification_output_accuracy: 0.6807 - val_classification_output_loss: 0.9505 - val_ecg_bilstm_output_loss: 0.0361 - val_eda_latent_driver_output_loss: 1.0046e-04 - val_loss: 0.9893 - val_resp_cycle_detection_output_loss: 5.6388e-05\n",
            "Epoch 59/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3s/step - classification_output_accuracy: 0.9426 - classification_output_loss: 0.2036 - ecg_bilstm_output_loss: 0.0355 - eda_latent_driver_output_loss: 1.3232e-04 - loss: 0.2393 - resp_cycle_detection_output_loss: 4.5417e-05 - val_classification_output_accuracy: 0.6719 - val_classification_output_loss: 1.0136 - val_ecg_bilstm_output_loss: 0.0369 - val_eda_latent_driver_output_loss: 1.0768e-04 - val_loss: 1.0528 - val_resp_cycle_detection_output_loss: 3.2136e-05\n",
            "Epoch 60/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - classification_output_accuracy: 0.9183 - classification_output_loss: 0.2339 - ecg_bilstm_output_loss: 0.0355 - eda_latent_driver_output_loss: 1.0772e-04 - loss: 0.2695 - resp_cycle_detection_output_loss: 3.8648e-05 - val_classification_output_accuracy: 0.6801 - val_classification_output_loss: 0.9639 - val_ecg_bilstm_output_loss: 0.0386 - val_eda_latent_driver_output_loss: 9.6611e-05 - val_loss: 1.0032 - val_resp_cycle_detection_output_loss: 3.4201e-05\n",
            "Epoch 61/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 3s/step - classification_output_accuracy: 0.9539 - classification_output_loss: 0.1743 - ecg_bilstm_output_loss: 0.0370 - eda_latent_driver_output_loss: 8.3793e-05 - loss: 0.2113 - resp_cycle_detection_output_loss: 2.3930e-05 - val_classification_output_accuracy: 0.6725 - val_classification_output_loss: 0.9998 - val_ecg_bilstm_output_loss: 0.0344 - val_eda_latent_driver_output_loss: 1.2175e-04 - val_loss: 1.0385 - val_resp_cycle_detection_output_loss: 1.7041e-05\n",
            "Epoch 62/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 3s/step - classification_output_accuracy: 0.9299 - classification_output_loss: 0.2120 - ecg_bilstm_output_loss: 0.0334 - eda_latent_driver_output_loss: 1.1753e-04 - loss: 0.2455 - resp_cycle_detection_output_loss: 1.5551e-05 - val_classification_output_accuracy: 0.6725 - val_classification_output_loss: 1.0424 - val_ecg_bilstm_output_loss: 0.0358 - val_eda_latent_driver_output_loss: 2.2246e-04 - val_loss: 1.0825 - val_resp_cycle_detection_output_loss: 1.0235e-05\n",
            "Epoch 63/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3s/step - classification_output_accuracy: 0.9522 - classification_output_loss: 0.1751 - ecg_bilstm_output_loss: 0.0345 - eda_latent_driver_output_loss: 2.2979e-04 - loss: 0.2099 - resp_cycle_detection_output_loss: 7.7409e-06 - val_classification_output_accuracy: 0.6725 - val_classification_output_loss: 1.0171 - val_ecg_bilstm_output_loss: 0.0361 - val_eda_latent_driver_output_loss: 1.0880e-04 - val_loss: 1.0559 - val_resp_cycle_detection_output_loss: 4.7374e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - classification_output_accuracy: 0.9608 - classification_output_loss: 0.1541 - ecg_bilstm_output_loss: 0.0356 - eda_latent_driver_output_loss: 1.0154e-04 - loss: 0.1898 - resp_cycle_detection_output_loss: 4.7536e-06 - val_classification_output_accuracy: 0.6971 - val_classification_output_loss: 1.0113 - val_ecg_bilstm_output_loss: 0.0363 - val_eda_latent_driver_output_loss: 7.2299e-05 - val_loss: 1.0510 - val_resp_cycle_detection_output_loss: 2.9343e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - classification_output_accuracy: 0.9504 - classification_output_loss: 0.1801 - ecg_bilstm_output_loss: 0.0354 - eda_latent_driver_output_loss: 8.9478e-05 - loss: 0.2156 - resp_cycle_detection_output_loss: 2.8280e-06 - val_classification_output_accuracy: 0.6830 - val_classification_output_loss: 1.0231 - val_ecg_bilstm_output_loss: 0.0359 - val_eda_latent_driver_output_loss: 9.5503e-05 - val_loss: 1.0637 - val_resp_cycle_detection_output_loss: 1.7039e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - classification_output_accuracy: 0.9702 - classification_output_loss: 0.1436 - ecg_bilstm_output_loss: 0.0355 - eda_latent_driver_output_loss: 1.1267e-04 - loss: 0.1792 - resp_cycle_detection_output_loss: 1.5764e-06 - val_classification_output_accuracy: 0.6784 - val_classification_output_loss: 1.0573 - val_ecg_bilstm_output_loss: 0.0363 - val_eda_latent_driver_output_loss: 9.8932e-05 - val_loss: 1.0974 - val_resp_cycle_detection_output_loss: 6.8246e-07\n",
            "Epoch 67/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - classification_output_accuracy: 0.9708 - classification_output_loss: 0.1333 - ecg_bilstm_output_loss: 0.0360 - eda_latent_driver_output_loss: 1.2933e-04 - loss: 0.1695 - resp_cycle_detection_output_loss: 6.4843e-07 - val_classification_output_accuracy: 0.6895 - val_classification_output_loss: 1.0305 - val_ecg_bilstm_output_loss: 0.0348 - val_eda_latent_driver_output_loss: 9.8194e-05 - val_loss: 1.0692 - val_resp_cycle_detection_output_loss: 3.6771e-07\n",
            "Epoch 68/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - classification_output_accuracy: 0.9784 - classification_output_loss: 0.1080 - ecg_bilstm_output_loss: 0.0349 - eda_latent_driver_output_loss: 7.9725e-05 - loss: 0.1430 - resp_cycle_detection_output_loss: 3.1464e-07 - val_classification_output_accuracy: 0.7006 - val_classification_output_loss: 1.0169 - val_ecg_bilstm_output_loss: 0.0372 - val_eda_latent_driver_output_loss: 7.5454e-05 - val_loss: 1.0591 - val_resp_cycle_detection_output_loss: 1.9381e-07\n",
            "Epoch 69/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - classification_output_accuracy: 0.9892 - classification_output_loss: 0.0874 - ecg_bilstm_output_loss: 0.0355 - eda_latent_driver_output_loss: 8.0743e-05 - loss: 0.1231 - resp_cycle_detection_output_loss: 1.7389e-07 - val_classification_output_accuracy: 0.6801 - val_classification_output_loss: 1.0976 - val_ecg_bilstm_output_loss: 0.0374 - val_eda_latent_driver_output_loss: 6.2561e-05 - val_loss: 1.1414 - val_resp_cycle_detection_output_loss: 1.3120e-07\n",
            "Epoch 70/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - classification_output_accuracy: 0.9762 - classification_output_loss: 0.1088 - ecg_bilstm_output_loss: 0.0361 - eda_latent_driver_output_loss: 7.0729e-05 - loss: 0.1449 - resp_cycle_detection_output_loss: 9.4785e-08 - val_classification_output_accuracy: 0.6848 - val_classification_output_loss: 1.1198 - val_ecg_bilstm_output_loss: 0.0363 - val_eda_latent_driver_output_loss: 1.0966e-04 - val_loss: 1.1631 - val_resp_cycle_detection_output_loss: 4.7788e-08\n",
            "Epoch 71/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - classification_output_accuracy: 0.9748 - classification_output_loss: 0.1029 - ecg_bilstm_output_loss: 0.0360 - eda_latent_driver_output_loss: 9.2912e-05 - loss: 0.1389 - resp_cycle_detection_output_loss: 3.8326e-08 - val_classification_output_accuracy: 0.6830 - val_classification_output_loss: 1.1174 - val_ecg_bilstm_output_loss: 0.0377 - val_eda_latent_driver_output_loss: 1.4781e-04 - val_loss: 1.1597 - val_resp_cycle_detection_output_loss: 1.8628e-08\n",
            "Epoch 72/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - classification_output_accuracy: 0.9812 - classification_output_loss: 0.1010 - ecg_bilstm_output_loss: 0.0374 - eda_latent_driver_output_loss: 1.0533e-04 - loss: 0.1385 - resp_cycle_detection_output_loss: 1.8194e-08 - val_classification_output_accuracy: 0.6871 - val_classification_output_loss: 1.0775 - val_ecg_bilstm_output_loss: 0.0367 - val_eda_latent_driver_output_loss: 7.5945e-05 - val_loss: 1.1203 - val_resp_cycle_detection_output_loss: 8.9551e-09\n",
            "Epoch 73/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3s/step - classification_output_accuracy: 0.9781 - classification_output_loss: 0.0942 - ecg_bilstm_output_loss: 0.0360 - eda_latent_driver_output_loss: 7.5429e-05 - loss: 0.1303 - resp_cycle_detection_output_loss: 7.9795e-09 - val_classification_output_accuracy: 0.6854 - val_classification_output_loss: 1.1144 - val_ecg_bilstm_output_loss: 0.0374 - val_eda_latent_driver_output_loss: 7.3171e-05 - val_loss: 1.1578 - val_resp_cycle_detection_output_loss: 3.8884e-09\n",
            "Epoch 74/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - classification_output_accuracy: 0.9730 - classification_output_loss: 0.1150 - ecg_bilstm_output_loss: 0.0361 - eda_latent_driver_output_loss: 1.6571e-04 - loss: 0.1513 - resp_cycle_detection_output_loss: 3.6989e-09 - val_classification_output_accuracy: 0.6585 - val_classification_output_loss: 1.2843 - val_ecg_bilstm_output_loss: 0.0356 - val_eda_latent_driver_output_loss: 1.9875e-04 - val_loss: 1.3295 - val_resp_cycle_detection_output_loss: 1.9683e-09\n",
            "Epoch 75/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - classification_output_accuracy: 0.9378 - classification_output_loss: 0.1977 - ecg_bilstm_output_loss: 0.0355 - eda_latent_driver_output_loss: 2.2026e-04 - loss: 0.2334 - resp_cycle_detection_output_loss: 1.7916e-09 - val_classification_output_accuracy: 0.6421 - val_classification_output_loss: 1.3148 - val_ecg_bilstm_output_loss: 0.0410 - val_eda_latent_driver_output_loss: 1.3357e-04 - val_loss: 1.3637 - val_resp_cycle_detection_output_loss: 1.3269e-09\n",
            "Epoch 76/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 3s/step - classification_output_accuracy: 0.9088 - classification_output_loss: 0.2502 - ecg_bilstm_output_loss: 0.0372 - eda_latent_driver_output_loss: 1.2733e-04 - loss: 0.2875 - resp_cycle_detection_output_loss: 9.4663e-10 - val_classification_output_accuracy: 0.6503 - val_classification_output_loss: 1.1784 - val_ecg_bilstm_output_loss: 0.0345 - val_eda_latent_driver_output_loss: 1.2319e-04 - val_loss: 1.2143 - val_resp_cycle_detection_output_loss: 4.1319e-10\n",
            "Epoch 77/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 3s/step - classification_output_accuracy: 0.9741 - classification_output_loss: 0.1147 - ecg_bilstm_output_loss: 0.0336 - eda_latent_driver_output_loss: 9.6395e-05 - loss: 0.1484 - resp_cycle_detection_output_loss: 3.1164e-10 - val_classification_output_accuracy: 0.6614 - val_classification_output_loss: 1.1848 - val_ecg_bilstm_output_loss: 0.0344 - val_eda_latent_driver_output_loss: 8.8574e-05 - val_loss: 1.2218 - val_resp_cycle_detection_output_loss: 1.8702e-10\n",
            "Epoch 78/80\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3s/step - classification_output_accuracy: 0.9870 - classification_output_loss: 0.0805 - ecg_bilstm_output_loss: 0.0343 - eda_latent_driver_output_loss: 8.6131e-05 - loss: 0.1148 - resp_cycle_detection_output_loss: 1.5847e-10 - val_classification_output_accuracy: 0.6801 - val_classification_output_loss: 1.1585 - val_ecg_bilstm_output_loss: 0.0351 - val_eda_latent_driver_output_loss: 8.0301e-05 - val_loss: 1.1992 - val_resp_cycle_detection_output_loss: 6.4180e-11\n",
            "PINN model training initiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d0ed682"
      },
      "source": [
        "## Evaluate PINN Model Performance\n",
        "\n",
        "**Reasoning**:\n",
        "Now that the PINN model has been trained, I will evaluate its performance on the held-out test dataset. This involves calculating key metrics like the multi-class ROC-AUC score to understand the model's ability to distinguish between classes, and a confusion matrix to visualize the per-class accuracy and identify common misclassifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1efcb1ce",
        "outputId": "ec68f293-979e-4051-89cb-d1cbaabbd36e"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# 1. Use the trained model to make predictions on the test input data\n",
        "# The model outputs a list: [classification_output, eda_latent_output, resp_cycle_output, ecg_bilstm_output]\n",
        "# We are interested in the first output which is the classification_output (probabilities)\n",
        "y_pred_all_outputs = model.predict([X_test_ecg, X_test_resp, X_test_eda])\n",
        "classification_probabilities = y_pred_all_outputs[0]\n",
        "\n",
        "# 2. Convert the predicted probabilities into hard class labels\n",
        "y_pred_labels = np.argmax(classification_probabilities, axis=1)\n",
        "\n",
        "# 3. Calculate the multi-class ROC-AUC score\n",
        "# Check if y_test contains more than one class to compute AUC\n",
        "if len(np.unique(y_test)) > 1:\n",
        "    roc_auc = roc_auc_score(y_test, classification_probabilities, multi_class='ovr', average='weighted')\n",
        "    print(f\"\\nMulti-class ROC-AUC Score: {roc_auc:.4f}\")\n",
        "else:\n",
        "    print(\"\\nROC-AUC score cannot be calculated for a single class.\")\n",
        "\n",
        "# 4. Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
        "\n",
        "# 5. Print the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 383ms/step\n",
            "\n",
            "Multi-class ROC-AUC Score: 0.8685\n",
            "\n",
            "Confusion Matrix:\n",
            "[[637  78  49  14  34]\n",
            " [ 89 240   4   9  10]\n",
            " [ 88   6 100   2   4]\n",
            " [ 67  14   1  26   3]\n",
            " [ 35   8   2   4 187]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f71b5a5a"
      },
      "source": [
        "### Visualize ROC Curves\n",
        "\n",
        "To gain a deeper understanding of the PINN model's performance across different classes, a ROC curve visualization will show the trade-off between the True Positive Rate (TPR) and False Positive Rate (FPR) at various threshold settings for each class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "b91de485",
        "outputId": "552aef69-7e38-4417-92e0-3b8cec689d0e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Binarize the true labels for multi-class ROC calculation\n",
        "# Ensure y_test contains all unique labels to correctly binarize\n",
        "num_classes = len(np.unique(y_test))\n",
        "if num_classes > 2: # For multiclass, binarize labels\n",
        "    y_test_binarized = label_binarize(y_test, classes=np.arange(num_classes))\n",
        "else: # For binary classification, use original labels directly or expand to 2 classes\n",
        "    y_test_binarized = y_test # Assuming y_test is already 0 or 1\n",
        "    if num_classes == 1: # Handle case where only one class is present in y_test_binarized\n",
        "        print(\"Warning: Only one class present in y_test. ROC curve cannot be plotted.\")\n",
        "        # Optionally, you can skip plotting or handle this edge case differently.\n",
        "        # For now, we'll proceed but the plot might be trivial or erroneous.\n",
        "        if np.unique(y_test)[0] == 0:\n",
        "            y_test_binarized = np.hstack((np.ones((len(y_test), 1)), np.zeros((len(y_test), 1))))\n",
        "        else:\n",
        "            y_test_binarized = np.hstack((np.zeros((len(y_test), 1)), np.ones((len(y_test), 1))))\n",
        "        num_classes = 2 # Adjust num_classes for plotting logic\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "for i in range(num_classes):\n",
        "    if num_classes > 2:\n",
        "        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], classification_probabilities[:, i])\n",
        "    else:\n",
        "        # For binary, if y_test_binarized is 1D, roc_curve expects positive class probabilities\n",
        "        # y_test_binarized should be 0 or 1, classification_probabilities[:, 1] for positive class\n",
        "        fpr, tpr, _ = roc_curve(y_test, classification_probabilities[:, 1]) # Assuming class 1 is the positive class\n",
        "        # Only plot once for binary case, as 'i' might just be 0\n",
        "        if i > 0: # Skip if it's the second iteration in binary, already plotted\n",
        "            continue\n",
        "\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve of Class {i} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing (AUC = 0.50)')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Multi-class Classification')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60e4a66c"
      },
      "source": [
        "### Interpretation of ROC Curve Visualization\n",
        "\n",
        "**Reasoning**:\n",
        "This section provides an interpretation of the generated ROC curve plot, explaining what the curves and AUC values signify for the model's performance in distinguishing between classes.\n",
        "\n",
        "**Interpretation**:\n",
        "\n",
        "The ROC curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings. The Area Under the Curve (AUC) provides an aggregate measure of performance across all possible classification thresholds.\n",
        "\n",
        "*   **Higher and Steeper Curves:** A curve that is closer to the top-left corner indicates better performance. This means the model achieves a high TPR (correctly identifies positive instances) while maintaining a low FPR (minimizing false alarms).\n",
        "*   **AUC Values:**\n",
        "    *   An AUC of 1.0 indicates a perfect classifier.\n",
        "    *   An AUC of 0.5 indicates a classifier that performs no better than random guessing (represented by the dashed diagonal line).\n",
        "    *   AUC values between 0.5 and 1.0 suggest varying degrees of better-than-random performance.\n",
        "\n",
        "From the generated plot, you can:\n",
        "\n",
        "*   **Compare Class Performance:** Observe which classes have ROC curves closer to the top-left corner and higher AUC values. These are the classes that the model distinguishes most effectively from the other classes.\n",
        "*   **Identify Weaknesses:** If any class has an ROC curve close to the diagonal line or a low AUC, it indicates that the model struggles to differentiate that class from others. This could be due to data imbalance, overlapping features, or the inherent difficulty of the classification task for that specific class.\n",
        "\n",
        "This visualization complements the confusion matrix by providing a threshold-independent measure of discriminative power for each class, which is particularly useful in multi-class scenarios.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5QqVpMbdc2pS",
        "8WOrfmtHPrHW",
        "siYd5eSVkWwE",
        "67316770",
        "p_iOgFfyDhlH",
        "rG6IdQzNJwWF",
        "7350ca98",
        "44b068c3",
        "4UNgJGibdsfh",
        "VrrPcvgHkPTw",
        "_DhUZBcskTn3",
        "yaqd-1L0Yw9Y",
        "wsSuEKUOBDtn",
        "618dc9f4",
        "d89a0494",
        "633a8ea4",
        "443eab73",
        "3dc781dc"
      ],
      "mount_file_id": "1hWNP9Bj2I9STk50YmCUPFj_wSpQWc_rX",
      "authorship_tag": "ABX9TyOpu2/5GUsuEvYCcEntQ0+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}